<!DOCTYPE html>
<html lang="vi">

<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>NLP</title>
  <meta name='description' content='CLB Tin Hoc ITMO Brain'>

  <link rel="canonical" href="http://localhost:4000/nlp/">
  <link rel="alternate" type="application/rss+xml" title="ITMO Brain" href="/feed.xml">

  <!-- Twitter Card -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="NLP – ITMO Brain">
  <meta name="twitter:description" content="">
  <meta name="twitter:image:src" content="http://localhost:4000/images/nlp.png">

  <!-- Facebook OpenGraph -->
  <meta property="og:title" content="NLP – ITMO Brain">
  <meta property="og:description" content="">
  <meta property="og:image" content="http://localhost:4000/images/nlp.png">

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.gstatic.com">

  <link rel="preload" href="https://fonts.googleapis.com/css2?family=Jost:wght@400;500;700;900&display=swap" as="style">

  <link href="https://fonts.googleapis.com/css2?family=Jost:wght@400;500;700;900&display=swap" rel="stylesheet">


  <!-- Ionicons -->
  <link rel="preload" href="https://unpkg.com/ionicons@4.2.2/dist/css/ionicons.min.css" as="style">

  <link href="https://unpkg.com/ionicons@4.2.2/dist/css/ionicons.min.css" rel="stylesheet">

  <script>
    
    if (localStorage.getItem("theme") === "dark") {
      document.documentElement.setAttribute("dark", "");
      document.documentElement.classList.add('dark-mode');
    }
    
  </script>

  <style>
  
  /*!------------------------------------------------------------------
[MAIN STYLESHEET]
-------------------------------------------------------------------*/:root{--brand-color: #0073ec;--white: #fff;--light-gray: #f0f0f0;--light-blue: #f3f7ff;--blue-gray: #716f8a;--gray: #9e9e9e;--dark: #0c101a;--dark-blue: #1e2740;--background-color: var(--white);--background-alt-color: var(--light-blue);--text-color: var(--dark-blue);--text-alt-color: var(--blue-gray);--heading-font-color: var(--dark-blue);--link-color: var(--dark-blue);--link-color-hover: var(--dark-blue);--button-color: var(--white);--button-background-color: var(--brand-color);--button-background-hover: #4f31c7;--border-color: var(--light-blue);--border-color-alt: var(--light-blue);--th-color: var(--light-gray);--tr-color: var(--light-gray);--syntax-highlighting-background: #f3f3f3}[dark]:root{--brand-color: #0073ec;--white: #fff;--light-gray: #f0f0f0;--gray: #9e9e9e;--dark: #111016;--background-color: var(--dark);--background-alt-color: #1a1a1f;--text-color: var(--gray);--text-alt-color: var(--gray);--heading-font-color: var(--light-gray);--link-color: var(--light-gray);--link-color-hover: var(--light-gray);--button-color: var(--white);--button-background-color: var(--brand-color);--button-background-hover: #4f31c7;--border-color: #252629;--border-color-alt: #080b12;--th-color: #18181d;--tr-color: #080b12;--syntax-highlighting-background: #080b12}.list-reset{list-style-type:none;margin:0;padding:0}.clearfix::after,.clearfix ::before{content:"";display:table;clear:both}.screen-reader-text{clip:rect(1px, 1px, 1px, 1px);height:1px;overflow:hidden;position:absolute !important;width:1px;word-wrap:normal !important}/*! normalize.css v8.0.0 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}h1{font-size:2em;margin:0.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace, monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace, monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-0.25em}sup{top:-0.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}button,[type="button"],[type="reset"],[type="submit"]{-webkit-appearance:button}button::-moz-focus-inner,[type="button"]::-moz-focus-inner,[type="reset"]::-moz-focus-inner,[type="submit"]::-moz-focus-inner{border-style:none;padding:0}button:-moz-focusring,[type="button"]:-moz-focusring,[type="reset"]:-moz-focusring,[type="submit"]:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:0.35em 0.75em 0.625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type="checkbox"],[type="radio"]{box-sizing:border-box;padding:0}[type="number"]::-webkit-inner-spin-button,[type="number"]::-webkit-outer-spin-button{height:auto}[type="search"]{-webkit-appearance:textfield;outline-offset:-2px}[type="search"]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}template{display:none}[hidden]{display:none}body,h1,h2,h3,h4,h5,h6,p,blockquote,pre,dl,dd,ol,ul,fieldset,legend,figure,hr{margin:0;padding:0}li>ul,li>ol{margin-bottom:0}table{border-collapse:collapse;border-spacing:0}h1,h2,h3,h4,h5,h6,ul,ol,dl,blockquote,p,address,hr,table,fieldset,figure,pre{margin-bottom:32px}ul,ol,dd{margin-left:16px}ul li,ol li{margin-bottom:10px}.highlight{margin-bottom:32px;background:var(--syntax-highlighting-background)}.highlighter-rouge .highlight{background:var(--syntax-highlighting-background)}.highlight .c{color:#998;font-style:italic}.highlight .err{color:#a61717;background-color:#e3d2d2}.highlight .k{font-weight:bold}.highlight .o{font-weight:bold}.highlight .cm{color:#998;font-style:italic}.highlight .cp{color:#999;font-weight:bold}.highlight .c1{color:#998;font-style:italic}.highlight .cs{color:#999;font-weight:bold;font-style:italic}.highlight .gd{color:#000;background-color:#fdd}.highlight .gd .x{color:#000;background-color:#faa}.highlight .ge{font-style:italic}.highlight .gr{color:#a00}.highlight .gh{color:#999}.highlight .gi{color:#000;background-color:#dfd}.highlight .gi .x{color:#000;background-color:#afa}.highlight .go{color:#888}.highlight .gp{color:#555}.highlight .gs{font-weight:bold}.highlight .gu{color:#aaa}.highlight .gt{color:#a00}.highlight .kc{font-weight:bold}.highlight .kd{font-weight:bold}.highlight .kp{font-weight:bold}.highlight .kr{font-weight:bold}.highlight .kt{color:#5d76bf;font-weight:bold}.highlight .m{color:#099}.highlight .s{color:#ec2355}.highlight .na{color:#008080}.highlight .nb{color:#0086B3}.highlight .nc{color:#5d76bf;font-weight:bold}.highlight .no{color:#008080}.highlight .ni{color:#800080}.highlight .ne{color:#900;font-weight:bold}.highlight .nf{color:#900;font-weight:bold}.highlight .nn{color:#555}.highlight .nt{color:#4d65dc}.highlight .nv{color:#008080}.highlight .ow{font-weight:bold}.highlight .w{color:#bbb}.highlight .mf{color:#099}.highlight .mh{color:#099}.highlight .mi{color:#099}.highlight .mo{color:#099}.highlight .sb{color:#ec2355}.highlight .sc{color:#ec2355}.highlight .sd{color:#ec2355}.highlight .s2{color:#ec2355}.highlight .se{color:#ec2355}.highlight .sh{color:#ec2355}.highlight .si{color:#ec2355}.highlight .sx{color:#ec2355}.highlight .sr{color:#009926}.highlight .s1{color:#ec2355}.highlight .ss{color:#990073}.highlight .bp{color:#999}.highlight .vc{color:#008080}.highlight .vg{color:#008080}.highlight .vi{color:#008080}.highlight .il{color:#099}.container{max-width:1140px;padding-left:16px;padding-right:16px;margin:0 auto}@media only screen and (max-width: 1140px){.container{max-width:1000px}}@media only screen and (max-width: 1024px){.container{max-width:740px}}@media only screen and (max-width: 768px){.container{max-width:560px}}@media only screen and (max-width: 576px){.container{max-width:480px;padding-left:calc(16px + 4px);padding-right:calc(16px + 4px)}}.row{display:flex;flex-wrap:wrap;flex:0 1 auto;flex-direction:row;box-sizing:border-box;margin-left:-16px;margin-right:-16px}.col{padding-left:16px;padding-right:16px}[class^="col-"]{flex:auto}.col-0{width:0%}.col-1{width:8.3333333333%}.col-2{width:16.6666666667%}.col-3{width:25%}.col-4{width:33.3333333333%}.col-5{width:41.6666666667%}.col-6{width:50%}.col-7{width:58.3333333333%}.col-8{width:66.6666666667%}.col-9{width:75%}.col-10{width:83.3333333333%}.col-11{width:91.6666666667%}.col-12{width:100%}.push-0{margin-left:0%}.push-1{margin-left:8.3333333333%}.push-2{margin-left:16.6666666667%}.push-3{margin-left:25%}.push-4{margin-left:33.3333333333%}.push-5{margin-left:41.6666666667%}.push-6{margin-left:50%}.push-7{margin-left:58.3333333333%}.push-8{margin-left:66.6666666667%}.push-9{margin-left:75%}.push-10{margin-left:83.3333333333%}.push-11{margin-left:91.6666666667%}.push-12{margin-left:100%}.pull-0{margin-right:0%}.pull-1{margin-right:8.3333333333%}.pull-2{margin-right:16.6666666667%}.pull-3{margin-right:25%}.pull-4{margin-right:33.3333333333%}.pull-5{margin-right:41.6666666667%}.pull-6{margin-right:50%}.pull-7{margin-right:58.3333333333%}.pull-8{margin-right:66.6666666667%}.pull-9{margin-right:75%}.pull-10{margin-right:83.3333333333%}.pull-11{margin-right:91.6666666667%}.pull-12{margin-right:100%}@media (max-width: 1024px){.col-d-0{width:0%}.col-d-1{width:8.3333333333%}.col-d-2{width:16.6666666667%}.col-d-3{width:25%}.col-d-4{width:33.3333333333%}.col-d-5{width:41.6666666667%}.col-d-6{width:50%}.col-d-7{width:58.3333333333%}.col-d-8{width:66.6666666667%}.col-d-9{width:75%}.col-d-10{width:83.3333333333%}.col-d-11{width:91.6666666667%}.col-d-12{width:100%}.push-d-0{margin-left:0%}.push-d-1{margin-left:8.3333333333%}.push-d-2{margin-left:16.6666666667%}.push-d-3{margin-left:25%}.push-d-4{margin-left:33.3333333333%}.push-d-5{margin-left:41.6666666667%}.push-d-6{margin-left:50%}.push-d-7{margin-left:58.3333333333%}.push-d-8{margin-left:66.6666666667%}.push-d-9{margin-left:75%}.push-d-10{margin-left:83.3333333333%}.push-d-11{margin-left:91.6666666667%}.push-d-12{margin-left:100%}.pull-d-0{margin-right:0%}.pull-d-1{margin-right:8.3333333333%}.pull-d-2{margin-right:16.6666666667%}.pull-d-3{margin-right:25%}.pull-d-4{margin-right:33.3333333333%}.pull-d-5{margin-right:41.6666666667%}.pull-d-6{margin-right:50%}.pull-d-7{margin-right:58.3333333333%}.pull-d-8{margin-right:66.6666666667%}.pull-d-9{margin-right:75%}.pull-d-10{margin-right:83.3333333333%}.pull-d-11{margin-right:91.6666666667%}.pull-d-12{margin-right:100%}}@media (max-width: 768px){.col-t-0{width:0%}.col-t-1{width:8.3333333333%}.col-t-2{width:16.6666666667%}.col-t-3{width:25%}.col-t-4{width:33.3333333333%}.col-t-5{width:41.6666666667%}.col-t-6{width:50%}.col-t-7{width:58.3333333333%}.col-t-8{width:66.6666666667%}.col-t-9{width:75%}.col-t-10{width:83.3333333333%}.col-t-11{width:91.6666666667%}.col-t-12{width:100%}.push-t-0{margin-left:0%}.push-t-1{margin-left:8.3333333333%}.push-t-2{margin-left:16.6666666667%}.push-t-3{margin-left:25%}.push-t-4{margin-left:33.3333333333%}.push-t-5{margin-left:41.6666666667%}.push-t-6{margin-left:50%}.push-t-7{margin-left:58.3333333333%}.push-t-8{margin-left:66.6666666667%}.push-t-9{margin-left:75%}.push-t-10{margin-left:83.3333333333%}.push-t-11{margin-left:91.6666666667%}.push-t-12{margin-left:100%}.pull-t-0{margin-right:0%}.pull-t-1{margin-right:8.3333333333%}.pull-t-2{margin-right:16.6666666667%}.pull-t-3{margin-right:25%}.pull-t-4{margin-right:33.3333333333%}.pull-t-5{margin-right:41.6666666667%}.pull-t-6{margin-right:50%}.pull-t-7{margin-right:58.3333333333%}.pull-t-8{margin-right:66.6666666667%}.pull-t-9{margin-right:75%}.pull-t-10{margin-right:83.3333333333%}.pull-t-11{margin-right:91.6666666667%}.pull-t-12{margin-right:100%}}@media (max-width: 576px){.col-m-0{width:0%}.col-m-1{width:8.3333333333%}.col-m-2{width:16.6666666667%}.col-m-3{width:25%}.col-m-4{width:33.3333333333%}.col-m-5{width:41.6666666667%}.col-m-6{width:50%}.col-m-7{width:58.3333333333%}.col-m-8{width:66.6666666667%}.col-m-9{width:75%}.col-m-10{width:83.3333333333%}.col-m-11{width:91.6666666667%}.col-m-12{width:100%}.push-m-0{margin-left:0%}.push-m-1{margin-left:8.3333333333%}.push-m-2{margin-left:16.6666666667%}.push-m-3{margin-left:25%}.push-m-4{margin-left:33.3333333333%}.push-m-5{margin-left:41.6666666667%}.push-m-6{margin-left:50%}.push-m-7{margin-left:58.3333333333%}.push-m-8{margin-left:66.6666666667%}.push-m-9{margin-left:75%}.push-m-10{margin-left:83.3333333333%}.push-m-11{margin-left:91.6666666667%}.push-m-12{margin-left:100%}.pull-m-0{margin-right:0%}.pull-m-1{margin-right:8.3333333333%}.pull-m-2{margin-right:16.6666666667%}.pull-m-3{margin-right:25%}.pull-m-4{margin-right:33.3333333333%}.pull-m-5{margin-right:41.6666666667%}.pull-m-6{margin-right:50%}.pull-m-7{margin-right:58.3333333333%}.pull-m-8{margin-right:66.6666666667%}.pull-m-9{margin-right:75%}.pull-m-10{margin-right:83.3333333333%}.pull-m-11{margin-right:91.6666666667%}.pull-m-12{margin-right:100%}}@media (max-width: 1024px){.col-d-0{width:0%}.col-d-1{width:8.3333333333%}.col-d-2{width:16.6666666667%}.col-d-3{width:25%}.col-d-4{width:33.3333333333%}.col-d-5{width:41.6666666667%}.col-d-6{width:50%}.col-d-7{width:58.3333333333%}.col-d-8{width:66.6666666667%}.col-d-9{width:75%}.col-d-10{width:83.3333333333%}.col-d-11{width:91.6666666667%}.col-d-12{width:100%}.push-d-0{margin-left:0%}.push-d-1{margin-left:8.3333333333%}.push-d-2{margin-left:16.6666666667%}.push-d-3{margin-left:25%}.push-d-4{margin-left:33.3333333333%}.push-d-5{margin-left:41.6666666667%}.push-d-6{margin-left:50%}.push-d-7{margin-left:58.3333333333%}.push-d-8{margin-left:66.6666666667%}.push-d-9{margin-left:75%}.push-d-10{margin-left:83.3333333333%}.push-d-11{margin-left:91.6666666667%}.push-d-12{margin-left:100%}.pull-d-0{margin-right:0%}.pull-d-1{margin-right:8.3333333333%}.pull-d-2{margin-right:16.6666666667%}.pull-d-3{margin-right:25%}.pull-d-4{margin-right:33.3333333333%}.pull-d-5{margin-right:41.6666666667%}.pull-d-6{margin-right:50%}.pull-d-7{margin-right:58.3333333333%}.pull-d-8{margin-right:66.6666666667%}.pull-d-9{margin-right:75%}.pull-d-10{margin-right:83.3333333333%}.pull-d-11{margin-right:91.6666666667%}.pull-d-12{margin-right:100%}}@media (max-width: 768px){.col-t-0{width:0%}.col-t-1{width:8.3333333333%}.col-t-2{width:16.6666666667%}.col-t-3{width:25%}.col-t-4{width:33.3333333333%}.col-t-5{width:41.6666666667%}.col-t-6{width:50%}.col-t-7{width:58.3333333333%}.col-t-8{width:66.6666666667%}.col-t-9{width:75%}.col-t-10{width:83.3333333333%}.col-t-11{width:91.6666666667%}.col-t-12{width:100%}.push-t-0{margin-left:0%}.push-t-1{margin-left:8.3333333333%}.push-t-2{margin-left:16.6666666667%}.push-t-3{margin-left:25%}.push-t-4{margin-left:33.3333333333%}.push-t-5{margin-left:41.6666666667%}.push-t-6{margin-left:50%}.push-t-7{margin-left:58.3333333333%}.push-t-8{margin-left:66.6666666667%}.push-t-9{margin-left:75%}.push-t-10{margin-left:83.3333333333%}.push-t-11{margin-left:91.6666666667%}.push-t-12{margin-left:100%}.pull-t-0{margin-right:0%}.pull-t-1{margin-right:8.3333333333%}.pull-t-2{margin-right:16.6666666667%}.pull-t-3{margin-right:25%}.pull-t-4{margin-right:33.3333333333%}.pull-t-5{margin-right:41.6666666667%}.pull-t-6{margin-right:50%}.pull-t-7{margin-right:58.3333333333%}.pull-t-8{margin-right:66.6666666667%}.pull-t-9{margin-right:75%}.pull-t-10{margin-right:83.3333333333%}.pull-t-11{margin-right:91.6666666667%}.pull-t-12{margin-right:100%}}@media (max-width: 576px){.col-m-0{width:0%}.col-m-1{width:8.3333333333%}.col-m-2{width:16.6666666667%}.col-m-3{width:25%}.col-m-4{width:33.3333333333%}.col-m-5{width:41.6666666667%}.col-m-6{width:50%}.col-m-7{width:58.3333333333%}.col-m-8{width:66.6666666667%}.col-m-9{width:75%}.col-m-10{width:83.3333333333%}.col-m-11{width:91.6666666667%}.col-m-12{width:100%}.push-m-0{margin-left:0%}.push-m-1{margin-left:8.3333333333%}.push-m-2{margin-left:16.6666666667%}.push-m-3{margin-left:25%}.push-m-4{margin-left:33.3333333333%}.push-m-5{margin-left:41.6666666667%}.push-m-6{margin-left:50%}.push-m-7{margin-left:58.3333333333%}.push-m-8{margin-left:66.6666666667%}.push-m-9{margin-left:75%}.push-m-10{margin-left:83.3333333333%}.push-m-11{margin-left:91.6666666667%}.push-m-12{margin-left:100%}.pull-m-0{margin-right:0%}.pull-m-1{margin-right:8.3333333333%}.pull-m-2{margin-right:16.6666666667%}.pull-m-3{margin-right:25%}.pull-m-4{margin-right:33.3333333333%}.pull-m-5{margin-right:41.6666666667%}.pull-m-6{margin-right:50%}.pull-m-7{margin-right:58.3333333333%}.pull-m-8{margin-right:66.6666666667%}.pull-m-9{margin-right:75%}.pull-m-10{margin-right:83.3333333333%}.pull-m-11{margin-right:91.6666666667%}.pull-m-12{margin-right:100%}}@media (max-width: 1024px){.col-d-0{width:0%}.col-d-1{width:8.3333333333%}.col-d-2{width:16.6666666667%}.col-d-3{width:25%}.col-d-4{width:33.3333333333%}.col-d-5{width:41.6666666667%}.col-d-6{width:50%}.col-d-7{width:58.3333333333%}.col-d-8{width:66.6666666667%}.col-d-9{width:75%}.col-d-10{width:83.3333333333%}.col-d-11{width:91.6666666667%}.col-d-12{width:100%}.push-d-0{margin-left:0%}.push-d-1{margin-left:8.3333333333%}.push-d-2{margin-left:16.6666666667%}.push-d-3{margin-left:25%}.push-d-4{margin-left:33.3333333333%}.push-d-5{margin-left:41.6666666667%}.push-d-6{margin-left:50%}.push-d-7{margin-left:58.3333333333%}.push-d-8{margin-left:66.6666666667%}.push-d-9{margin-left:75%}.push-d-10{margin-left:83.3333333333%}.push-d-11{margin-left:91.6666666667%}.push-d-12{margin-left:100%}.pull-d-0{margin-right:0%}.pull-d-1{margin-right:8.3333333333%}.pull-d-2{margin-right:16.6666666667%}.pull-d-3{margin-right:25%}.pull-d-4{margin-right:33.3333333333%}.pull-d-5{margin-right:41.6666666667%}.pull-d-6{margin-right:50%}.pull-d-7{margin-right:58.3333333333%}.pull-d-8{margin-right:66.6666666667%}.pull-d-9{margin-right:75%}.pull-d-10{margin-right:83.3333333333%}.pull-d-11{margin-right:91.6666666667%}.pull-d-12{margin-right:100%}}@media (max-width: 768px){.col-t-0{width:0%}.col-t-1{width:8.3333333333%}.col-t-2{width:16.6666666667%}.col-t-3{width:25%}.col-t-4{width:33.3333333333%}.col-t-5{width:41.6666666667%}.col-t-6{width:50%}.col-t-7{width:58.3333333333%}.col-t-8{width:66.6666666667%}.col-t-9{width:75%}.col-t-10{width:83.3333333333%}.col-t-11{width:91.6666666667%}.col-t-12{width:100%}.push-t-0{margin-left:0%}.push-t-1{margin-left:8.3333333333%}.push-t-2{margin-left:16.6666666667%}.push-t-3{margin-left:25%}.push-t-4{margin-left:33.3333333333%}.push-t-5{margin-left:41.6666666667%}.push-t-6{margin-left:50%}.push-t-7{margin-left:58.3333333333%}.push-t-8{margin-left:66.6666666667%}.push-t-9{margin-left:75%}.push-t-10{margin-left:83.3333333333%}.push-t-11{margin-left:91.6666666667%}.push-t-12{margin-left:100%}.pull-t-0{margin-right:0%}.pull-t-1{margin-right:8.3333333333%}.pull-t-2{margin-right:16.6666666667%}.pull-t-3{margin-right:25%}.pull-t-4{margin-right:33.3333333333%}.pull-t-5{margin-right:41.6666666667%}.pull-t-6{margin-right:50%}.pull-t-7{margin-right:58.3333333333%}.pull-t-8{margin-right:66.6666666667%}.pull-t-9{margin-right:75%}.pull-t-10{margin-right:83.3333333333%}.pull-t-11{margin-right:91.6666666667%}.pull-t-12{margin-right:100%}}@media (max-width: 576px){.col-m-0{width:0%}.col-m-1{width:8.3333333333%}.col-m-2{width:16.6666666667%}.col-m-3{width:25%}.col-m-4{width:33.3333333333%}.col-m-5{width:41.6666666667%}.col-m-6{width:50%}.col-m-7{width:58.3333333333%}.col-m-8{width:66.6666666667%}.col-m-9{width:75%}.col-m-10{width:83.3333333333%}.col-m-11{width:91.6666666667%}.col-m-12{width:100%}.push-m-0{margin-left:0%}.push-m-1{margin-left:8.3333333333%}.push-m-2{margin-left:16.6666666667%}.push-m-3{margin-left:25%}.push-m-4{margin-left:33.3333333333%}.push-m-5{margin-left:41.6666666667%}.push-m-6{margin-left:50%}.push-m-7{margin-left:58.3333333333%}.push-m-8{margin-left:66.6666666667%}.push-m-9{margin-left:75%}.push-m-10{margin-left:83.3333333333%}.push-m-11{margin-left:91.6666666667%}.push-m-12{margin-left:100%}.pull-m-0{margin-right:0%}.pull-m-1{margin-right:8.3333333333%}.pull-m-2{margin-right:16.6666666667%}.pull-m-3{margin-right:25%}.pull-m-4{margin-right:33.3333333333%}.pull-m-5{margin-right:41.6666666667%}.pull-m-6{margin-right:50%}.pull-m-7{margin-right:58.3333333333%}.pull-m-8{margin-right:66.6666666667%}.pull-m-9{margin-right:75%}.pull-m-10{margin-right:83.3333333333%}.pull-m-11{margin-right:91.6666666667%}.pull-m-12{margin-right:100%}}.animate{animation:animateElement cubic-bezier(0.3, 0.45, 0.45, 0.95) 0.75s;animation-duration:0.5s;animation-iteration-count:1;transition:transform .15s}@keyframes animateElement{0%{transform:translate(0px, 50px)}100%{transform:translate(0px, 0px)}}@keyframes pulse{0%{transform:scale(1, 1)}25%{transform:scale(1, 1)}50%{transform:scale(1.2, 1.2)}100%{transform:scale(1, 1)}}*,*::after,*::before{box-sizing:border-box}body{font-family:"Noto Sans KR",sans-serif;font-size:15px;line-height:1.5;overflow-x:hidden;color:var(--text-color);background-color:var(--background-color);-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}@media only screen and (max-width: 576px){body{font-size:18px}}*::selection{color:var(--white);background-color:var(--brand-color)}h1,h2,h3,h4,h5,h6{font-family:"Noto Sans KR",sans-serif;font-weight:700;line-height:1.3;letter-spacing:-1px;color:var(--heading-font-color)}h1{font-size:36px}h2{font-size:28px}h3{font-size:24px}h4{font-size:20px}h5{font-size:18px}h6{font-size:16px}blockquote{position:relative;margin:40px 0;padding-left:26px;font-size:24px;line-height:1.7;font-weight:900;border-left:4px solid var(--brand-color);color:var(--heading-font-color)}blockquote p{margin-bottom:5px}blockquote cite{display:inline-block;margin-top:8px;font-size:14px;font-weight:700;font-style:normal;color:var(--heading-font-color)}@media only screen and (max-width: 576px){blockquote{font-size:21px}}pre{overflow:auto;padding:15px;margin-bottom:0;font-size:14px;white-space:pre-wrap;word-wrap:break-word;word-break:break-all;color:var(--heading-font-color)}img,.lightense-wrap{max-width:100%;height:auto;vertical-align:middle}img+em,.lightense-wrap+em,.gallery+em{display:block;margin-top:20px;font-size:12px;line-height:22px;font-style:normal;font-weight:normal;text-align:center;color:var(--heading-font-color)}img+em a,.lightense-wrap+em a,.gallery+em a{font-weight:500;border-bottom:1px solid var(--border-color);transition:all 0.35s}img+em a:hover,.lightense-wrap+em a:hover,.gallery+em a:hover{color:var(--link-color);border-color:var(--link-color-hover)}@media only screen and (max-width: 576px){img+em,.lightense-wrap+em,.gallery+em{margin-top:12px}}a{text-decoration:none;color:var(--link-color);transition:all 0.35s}a:hover{color:var(--link-color-hover)}hr{width:100%;height:1px;margin:60px 0;border:0;background:var(--background-alt-color)}.table-container{display:block;max-width:100%;overflow-x:auto}table{font-size:12px;color:var(--dark);width:100%;border-width:1px;border-color:var(--background-alt-color);border-collapse:collapse;color:var(--heading-font-color)}table th{padding:10px;font-size:16px;text-align:left;border:1px solid var(--th-color);color:var(--heading-font-color);font-weight:700;background-color:var(--th-color)}table tr{background-color:var(--tr-color);transition:all .3s ease}table tr:nth-child(even){background-color:transparent}table td{padding:10px;font-size:14px;border:1px solid var(--background-alt-color)}.button{display:inline-block;padding:20px 26px;font-size:16px;font-weight:700;text-decoration:none;border-radius:2px;border:none;outline:none;cursor:pointer;transition:all .25s;color:var(--heading-font-color);background:var(--background-alt-color)}.button--primary{color:var(--white);background-color:var(--button-background-color)}.button--primary:hover{background:var(--button-background-hover)}.button--big{display:block;width:100%}.lazy{opacity:0;transition:opacity 0.3s ease-in-out}.lazy.loaded{opacity:1}.lightense-backdrop{background-color:var(--background-color) !important}.header .header__inner{position:relative;display:flex;align-items:center;flex-wrap:wrap;padding:16px 16px}@media only screen and (max-width: 1024px){.header .header__inner{padding:15px 16px}}@media only screen and (max-width: 576px){.header .header__inner{padding:15px 16px}}.logo__link{padding:4px 0;font-family:"Noto Sans KR",sans-serif;font-size:28px;letter-spacing:-1px;line-height:1;font-weight:700;transition:color .25s ease}.logo__link:hover{color:var(--brand-color)}.logo__image{max-height:50px}.main-nav{margin-left:auto}@media only screen and (max-width: 1024px){.main-nav{position:fixed;top:0;left:0;right:0;bottom:0;z-index:100;opacity:0;visibility:hidden;background-color:var(--background-color)}.main-nav.is-open{opacity:1;visibility:visible;transition:all .25s ease}.main-nav .nav__list{flex-direction:column;width:100%}.main-nav .nav__list .nav__item{display:block;margin:0}.main-nav .nav__list .nav__item.nav__item-icon{margin-right:0}.main-nav .nav__list .nav__item .nav__link{display:inline-block;padding:16px 0;font-size:18px;transition:color .25s ease}.main-nav .nav__list .nav__item .nav__link:hover{color:var(--brand-color)}}.main-nav__box{display:flex;align-items:center}.main-nav__box .nav__icon-close{display:none;justify-content:center;align-items:center;width:36px;height:36px;font-size:24px;line-height:1;border-radius:50%;color:var(--heading-font-color);background:var(--background-alt-color);cursor:pointer}.main-nav__box .nav__icon-close:hover .ion-md-close{transform:rotate(90deg)}.main-nav__box .nav__icon-close .ion-md-close{transition:all 0.35s}.main-nav__box .nav__title{display:none}@media only screen and (max-width: 1024px){.main-nav__box{display:block;align-items:center;width:80%;height:80vh;padding-top:180px;margin:0 auto;text-align:center;overflow-y:auto}.main-nav__box .nav__icon-close{display:flex;position:absolute;top:40px;right:40px}.main-nav__box .nav__title{display:inline-block;margin-bottom:12px;font-family:"Noto Sans KR", sans-serif;font-size:36px;font-weight:700;letter-spacing:-1px;color:var(--heading-font-color)}}@media only screen and (max-width: 768px){.main-nav__box{padding-top:100px}}.nav__list{display:flex;align-items:center}.nav__list .nav__item{display:inline-block;margin-right:48px;margin-bottom:0}.nav__list .nav__item.nav__item-icon{margin-right:12px}.nav__list .nav__item .nav__link{position:relative;padding:4px 0;font-size:16px;line-height:1;font-weight:700;transition:color .25s ease}.nav__list .nav__item .nav__link:hover{color:var(--brand-color)}.nav-button{font-size:21px;color:var(--link-color);cursor:pointer}.nav-button .icon__menu{display:none;margin-right:12px}.nav-button .icon__menu,.nav-button .icon__search{transition:color .25s ease}.nav-button .icon__menu:hover,.nav-button .icon__search:hover{color:var(--brand-color)}@media only screen and (max-width: 1024px){.nav-button{display:flex;align-items:center;margin-left:auto;font-size:24px}.nav-button .icon__menu{display:block}}.toggle-theme{position:relative;display:flex;justify-content:center;align-items:center;width:24px;height:24px;user-select:none;cursor:pointer}@media only screen and (max-width: 1024px){.toggle-theme{padding:20px 0}}.toggle-sun,.toggle-moon{position:absolute;font-size:20px;transition:color .25s ease;color:var(--heading-font-color)}.toggle-sun:hover,.toggle-moon:hover{color:var(--brand-color)}.toggle-sun{display:none}.dark-mode .toggle-sun{display:block}.dark-mode .toggle-moon{display:none}.search{position:fixed;top:0;left:0;right:0;bottom:0;z-index:-1;overflow:auto;opacity:0;background:var(--background-color);transition:all .25s ease}.search.is-visible{z-index:100;opacity:1;transition:all .25s ease}.search__box{max-width:540px;margin:0 auto;padding-top:120px}@media only screen and (max-width: 1024px){.search__box{padding-top:100px}}.search__group{position:relative;margin-bottom:48px}.search__group .search__close{position:absolute;right:28px;top:50%;transform:translateY(-50%);display:flex;align-items:center;justify-content:center;width:32px;height:32px;font-size:24px;line-height:1;border-radius:50%;color:var(--heading-font-color);cursor:pointer;will-change:transform;transition:all .25s;background:var(--background-color)}.search__group .search__close:hover{transform:translateY(-50%) rotate(90deg)}.search__group .search__close .ion-md-close{vertical-align:middle}.search__group .search__text{width:100%;padding:28px;font-size:20px;font-weight:700;line-height:24px;border:2px solid transparent;border-radius:2px;color:var(--heading-font-color);background-color:var(--background-alt-color);outline:0;transition:all .25s}.search__group .search__text::placeholder{font-weight:700;color:var(--heading-font-color)}.search__group .search__text:focus{border-color:var(--brand-color)}.search__group .search__text::-ms-clear{display:none}@media only screen and (max-width: 576px){.search__group{margin-bottom:32px}.search__group .search__text{padding:24px}}.search-results-list .no-results{width:100%;margin:0;text-align:center;color:var(--heading-font-color)}.pagination{margin-bottom:20px}@media only screen and (max-width: 576px){.pagination{margin-bottom:30px}}.pagination__inner{display:flex;justify-content:center;align-items:center}.pagination__list{display:flex;justify-content:space-between;align-items:center;width:100%;font-size:18px;font-weight:700;line-height:1;color:var(--text-color)}@media only screen and (max-width: 576px){.pagination__list{align-items:stretch;font-size:16px}}.pagination__item{display:flex;justify-content:center;align-items:center;width:100%;padding:24px 20px;text-align:center;border-radius:8px;background:var(--background-alt-color)}@media only screen and (max-width: 576px){.pagination__item{align-items:center;padding:20px;border-radius:8px}}.pagination__count{margin:0 32px;font-size:16px;color:var(--link-color)}@media only screen and (max-width: 768px){.pagination__count{margin:0 12px}}@media only screen and (max-width: 576px){.pagination__count{margin:0 8px;font-size:14px;line-height:1.2}}.pagination__next:hover,.pagination__prev:hover{color:var(--heading-font-color)}.pagination__next i,.pagination__prev i{font-size:15px;transition:transform .15s ease;will-change:transform}.pagination__next.disabled,.pagination__prev.disabled{opacity:0.64;cursor:not-allowed;color:inherit}.pagination__next.disabled:hover i,.pagination__prev.disabled:hover i{transform:none}.dark-mode .pagination__next.disabled,.dark-mode .pagination__prev.disabled{opacity:0.78}.pagination__next:hover i{transform:translateX(2px)}.pagination__next i{margin-left:5px}.pagination__prev:hover i{transform:translateX(-2px)}.pagination__prev i{margin-right:5px}.footer{margin-top:24px;background-color:var(--background-alt-color)}@media only screen and (max-width: 576px){.footer{margin-top:30px}}.footer__inner{padding:40px 0}.footer__inner .row .col{flex-grow:1}@media only screen and (max-width: 576px){.footer__inner{padding:30px 0}}@media only screen and (max-width: 1024px){.footer__author{margin-bottom:60px}}@media only screen and (max-width: 576px){.footer__author{margin-bottom:40px}}.footer__author-avatar{position:relative;width:105px;height:105px;margin-bottom:20px;transform:translate(0);border-radius:50%;overflow:hidden;box-shadow:0px 100px 80px rgba(0,0,0,0.07),0px 12.5216px 10.0172px rgba(0,0,0,0.035);background-color:var(--background-color)}.footer__author-avatar img{position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;user-select:none}.footer__author-name{margin-bottom:20px;font-size:32px;font-weight:900;line-height:1}.footer__author-bio{margin-bottom:0;color:var(--text-alt-color)}.social{margin-top:16px}.social .social__list{display:flex;align-items:center;flex-wrap:wrap}.social .social__list .social__item:first-child>.social__link{padding-left:0}.social .social__item{margin-bottom:0;margin-right:16px}.social .social__item:last-child{margin-right:0}.social .social__link{display:flex;align-items:center;padding:4px;font-size:20px;color:var(--heading-font-color)}.social .social__link:hover{color:var(--brand-color)}.footer__gallery .footer__gallery-title{margin-bottom:24px;font-size:28px}.footer__gallery .gallery__image img{height:100%;border-radius:8px;overflow:hidden}.footer__gallery .gallery__image img.lightense-open{border-radius:0}.footer__info{padding:24px 0;background-color:var(--background-color)}.footer__info .footer__info-box{display:flex;align-items:center;justify-content:space-between}@media only screen and (max-width: 1024px){.footer__info{padding:20px 0}}.copyright{margin-right:20px;font-size:14px;font-weight:500;color:var(--text-alt-color)}.copyright a{text-decoration:underline;text-decoration-color:transparent;color:var(--heading-font-color)}.copyright a:hover{text-decoration-color:var(--heading-font-color);color:var(--heading-font-color)}.top{min-width:36px;height:36px;font-size:20px;line-height:36px;text-align:center;border-radius:8px;color:var(--heading-font-color);background-color:var(--background-alt-color);cursor:pointer;transition:all .25s ease}.gallery-box{margin:32px 0}.gallery{display:grid;grid-template-columns:repeat(3, auto);justify-content:center;align-content:center;grid-gap:10px}.gallery .gallery__image{background:var(--background-color)}.gallery .gallery__image img{display:block;width:100%;height:auto;object-fit:cover}.hero{padding:20px 0;margin-bottom:20px;background-color:var(--background-alt-color)}@media only screen and (max-width: 576px){.hero{padding:30px 0;margin-bottom:30px}}.hero__inner{display:flex;align-items:center}@media only screen and (max-width: 1024px){.hero__inner{flex-direction:column}}.hero__left{max-width:450px;margin-right:auto}@media only screen and (max-width: 1140px){.hero__left{max-width:440px}}@media only screen and (max-width: 1024px){.hero__left{max-width:100%}}.hero__title{margin-bottom:20px;font-size:55px;font-weight:900;line-height:1.3;color:var(--heading-font-color)}@media only screen and (max-width: 1024px){.hero__title{font-size:50px}}@media only screen and (max-width: 768px){.hero__title{font-size:40px}}@media only screen and (max-width: 576px){.hero__title{font-size:32px}}.hero__description{margin-bottom:0;font-size:21px;color:var(--text-alt-color)}@media only screen and (max-width: 1024px){.hero__description{font-size:inherit}}.hero__subscribe{margin-top:32px}.hero__subscribe .subscribe-form{position:relative;border-radius:20px;background-color:var(--background-color)}.hero__subscribe .subscribe-email{width:100%;height:70px;padding:20px;font-size:16px;line-height:21px;border:2px solid transparent;border-radius:20px;outline:0;color:var(--heading-font-color);background-color:transparent;transition:all .25s ease}.hero__subscribe .subscribe-email::placeholder{opacity:0.6;color:var(--text-alt-color)}.hero__subscribe .subscribe-email:focus{border-color:var(--brand-color)}.hero__subscribe .subscribe-button{position:absolute;top:6px;right:6px;border-radius:20px}@media only screen and (max-width: 1024px){.hero__subscribe{margin-top:24px}}@media only screen and (max-width: 576px){.hero__subscribe{margin-top:20px}.hero__subscribe .subscribe-form{display:flex;flex-direction:column;padding:6px}.hero__subscribe .subscribe-email{height:56px;margin-bottom:4px}.hero__subscribe .subscribe-button{position:relative;top:0;right:0}}.hero__right{width:50%}@media only screen and (max-width: 1024px){.hero__right{width:100%;margin-top:40px}}@media only screen and (max-width: 576px){.hero__right{margin-top:32px}}.hero__image{position:relative;transform:translate(0);width:100%;height:410px;border-radius:8px;overflow:hidden;box-shadow:0 10px 30px rgba(0,0,0,0.02);background-color:var(--background-color);user-select:none}.hero__image img{position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover}@media only screen and (max-width: 1140px){.hero__image{height:380px}}@media only screen and (max-width: 1024px){.hero__image{height:440px}}@media only screen and (max-width: 768px){.hero__image{height:420px}}@media only screen and (max-width: 576px){.hero__image{height:280px}}.article{margin-bottom:32px;will-change:transform;transition:transform .2s}.article:hover{transform:translateY(-3px)}.article:hover .article__title a{text-decoration:underline;text-decoration-color:var(--link-color-hover);text-decoration-thickness:2px}.article__head{position:relative}.article__date{position:absolute;z-index:1;top:16px;left:16px;display:inline-block;padding:8px 12px;font-size:12px;line-height:1;font-weight:500;border-radius:4px;color:var(--heading-font-color);background:var(--background-color);pointer-events:none}.article__image{position:relative;transform:translate(0);display:block;height:0;margin-bottom:24px;padding-bottom:62%;border-radius:8px;overflow:hidden;background:var(--background-alt-color)}.article__image img{position:absolute;width:100%;height:100%;object-fit:cover;user-select:none}.video-icon{position:absolute;z-index:1;top:50%;left:50%;width:50%;height:50%;transform:translate(-50%, -50%);pointer-events:none}.video-icon .circle{width:50px;height:50px;position:absolute;top:0;left:0;right:0;bottom:0;border-radius:50%;overflow:hidden;margin:auto;transform:scale(1, 1)}.video-icon .circle.pulse{animation-timing-function:ease;animation:pulse 2s infinite;background-color:rgba(255,255,255,0.25)}.video-icon svg{fill:rgba(255,255,255,0.25);stroke:var(--light-blue);stroke-linejoin:round;stroke-width:5;backdrop-filter:blur(3.5px);-webkit-backdrop-filter:blur(4.5px);transition:all 0.3s}.article__title{margin-bottom:12px;font-size:24px}.article__title a{text-decoration:underline;text-decoration-color:transparent;text-decoration-thickness:2px}.article__title a:hover{color:var(--heading-font-color)}.article__excerpt{margin-bottom:0;font-size:16px;color:var(--text-alt-color)}.contact-head{margin-bottom:32px}.form__group{margin-bottom:20px}.form__group:last-child{margin-bottom:0}.form__input{width:100%;padding:20px;font-size:16px;font-weight:400;border:2px solid var(--border-color);border-radius:2px;outline:0;transition:.25s ease-in-out;resize:vertical;color:var(--heading-font-color);background-color:var(--background-alt-color)}.form__input::placeholder{color:var(--text-alt-color)}.form__input:focus{border-color:var(--brand-color)}.section__head{position:relative;display:flex;align-items:center;justify-content:space-between;flex-wrap:wrap;margin-bottom:40px}.section__head::after{content:"";position:absolute;z-index:-1;display:block;width:100%;height:1px;background:var(--background-alt-color);pointer-events:none}@media only screen and (max-width: 768px){.section__head::after{content:none}}.section__title{padding-right:20px;margin-bottom:0;font-size:28px}@media only screen and (max-width: 576px){.section__title{font-size:24px}}.section__link{padding-left:20px;font-size:18px;font-weight:500;text-decoration:underline;text-decoration-color:transparent;color:var(--link-color);transition:text-decoration .35s}.section__link:hover{text-decoration-color:var(--heading-font-color);color:var(--link-color-hover)}@media only screen and (max-width: 768px){.section__link{padding-left:0}}@media only screen and (max-width: 576px){.section__link{font-size:16px}}.section__title,.section__link{background:var(--background-color)}@media only screen and (max-width: 576px){.section-tags .row .col:last-child>.tag-image{margin-bottom:0}}.tag-image{margin-bottom:16px;position:relative;transform:translate(0);display:block;height:0;padding-bottom:62%;border-radius:8px;overflow:hidden;background:var(--background-alt-color);transition:transform .2s}.tag-image:hover{transform:translateY(-3px)}.tag-image img{position:absolute;width:100%;height:100%;object-fit:cover;user-select:none}.tag-image .tag-name{position:absolute;top:50%;left:50%;transform:translate(-50%, -50%);z-index:1;max-width:90%;display:inline-block;padding:8px 12px;font-size:14px;line-height:1;font-weight:700;text-transform:capitalize;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;border-radius:4px;color:var(--heading-font-color);background:var(--background-color);pointer-events:none}.post-head,.page-head{margin-bottom:48px}.post-head .row,.page-head .row{align-items:center}@media only screen and (max-width: 1024px){.post-head,.page-head{margin-bottom:40px}}@media only screen and (max-width: 576px){.post-head,.page-head{margin-bottom:32px}}.post-image,.page-image{position:relative;transform:translate(0);padding-top:90%;min-height:280px;border-radius:8px;overflow:hidden;background:var(--background-alt-color)}.post-image img,.page-image img{position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;user-select:none}@media only screen and (max-width: 1024px){.post-image,.page-image{padding-top:65%;margin-bottom:40px}}@media only screen and (max-width: 576px){.post-image,.page-image{margin-bottom:32px}}.page-image{padding-top:56.25%;margin-bottom:48px}@media only screen and (max-width: 1024px){.page-image{margin-bottom:40px}}@media only screen and (max-width: 576px){.page-image{margin-bottom:32px}}.post-video,.page-video{margin-bottom:48px;border-radius:8px;overflow:hidden;transform:translate(0);background-color:var(--background-alt-color)}.post-video .post-video__wrap,.post-video .page-video__wrap,.page-video .post-video__wrap,.page-video .page-video__wrap{position:relative;width:100%;height:0;padding-bottom:56.25%}.post-video .post-video__wrap iframe,.post-video .page-video__wrap iframe,.page-video .post-video__wrap iframe,.page-video .page-video__wrap iframe{position:absolute;top:0;left:0;width:100%;height:100%}@media only screen and (max-width: 1024px){.post-video,.page-video{margin-bottom:40px}}@media only screen and (max-width: 576px){.post-video,.page-video{margin-bottom:32px}}.post__info{margin-left:44px}.post__info.post__info-video{max-width:760px;margin:0 auto}@media only screen and (max-width: 1024px){.post__info{margin-left:0}}.page__info{max-width:760px;margin:0 auto}.post__tags{display:flex;align-items:center;flex-wrap:wrap;margin-bottom:20px}.post__tags .post__tag{padding:12px 16px;margin:4px 8px 4px 0;font-size:14px;line-height:1;font-weight:500;text-transform:capitalize;border:none;border-radius:8px;color:var(--heading-font-color);transition:none;background-color:var(--background-alt-color)}.post__tags .post__tag:last-child{margin-right:0}@media only screen and (max-width: 576px){.post__tags{margin-bottom:16px}}.post__title,.page__title{margin-bottom:24px;font-size:46px;line-height:1.2;font-weight:900}@media only screen and (max-width: 576px){.post__title,.page__title{margin-bottom:20px;font-size:32px}}.page__title{margin-bottom:0}.post__meta{display:flex;align-items:center;line-height:1}.post__meta .post__author-image{position:relative;transform:translate(0);width:50px;height:50px;border-radius:50%;overflow:hidden;margin-right:12px;background-color:var(--background-alt-color)}.post__meta .post__author-image img{position:absolute;top:0;left:0;width:100%;height:100%;object-fit:cover;user-select:none}.post__meta .post__meta-bottom{display:flex;flex-direction:column}.post__meta .post__author{display:inline-block;margin-bottom:7px;font-size:16px;font-weight:500;text-decoration:underline;text-decoration-color:transparent;color:var(--heading-font-color);transition:text-decoration-color .35s}.post__meta .post__author:hover{text-decoration-color:var(--heading-font-color)}.post__meta .post__date{font-size:14px;font-weight:400;color:var(--text-alt-color)}.post,.page{max-width:760px;margin:0 auto 60px;color:var(--text-color)}.post a,.page a{font-weight:500;border-bottom:1px solid var(--border-color)}.post a:hover,.page a:hover{color:var(--link-color);border-bottom-color:var(--link-color-hover)}.post img,.post .js-reframe,.page img,.page .js-reframe{border-radius:8px;overflow:hidden}.post img.lightense-open,.post .js-reframe.lightense-open,.page img.lightense-open,.page .js-reframe.lightense-open{border-radius:0}.post img[src$='#wide'],.page img[src$='#wide']{display:block;width:100vw;max-width:none;margin-left:50%;transform:translateX(-50%);border-radius:0;pointer-events:none;user-select:none}.post .button,.page .button{border:none;text-decoration:none}.post__share .share__list{display:flex;align-items:center;width:100%}.post__share .share__item{width:25%;margin-right:8px;margin-bottom:0;text-align:center}.post__share .share__item:last-child{margin-right:0}.post__share .share__link{display:flex;justify-content:center;align-items:center;width:100%;height:54px;font-size:18px;text-transform:uppercase;border:none;border-radius:8px;background:var(--background-alt-color)}.post__share .share__link i{transition:transform .25s;will-change:transform}.post__share .share__link:hover{color:var(--heading-font-color)}.post__share .share__link:hover i{transform:scale(1.1)}.related-posts{display:none;margin-top:10px}.related-posts.is-related{display:block}.related-posts .related-tag{text-transform:capitalize}@media only screen and (max-width: 576px){.related-posts{margin-top:10px}.related-posts .row .col:last-child{margin-bottom:0}}.show-comments{margin:12px 0 10px;text-align:center}.show-comments .disqus-button{padding:14px;border-radius:8px;text-decoration:underline;text-decoration-color:transparent}.show-comments .disqus-button:hover{text-decoration-color:var(--heading-font-color)}@media only screen and (max-width: 576px){.show-comments{margin:10px 0 0}.show-comments .disqus-button{padding:12px}}.post__comments{max-width:760px;margin:0 auto}.post__comments.is-open{margin:0 auto 32px}@media only screen and (max-width: 576px){.post__comments.is-open{margin:0 auto}}.error{text-align:center}.error .error__title{margin-bottom:24px;font-size:100px;line-height:1}.error .error__text{margin-bottom:0;color:var(--text-alt-color)}@media only screen and (max-width: 576px){.error .error__title{font-size:68px}}.recent-posts{margin-top:40px}@media only screen and (max-width: 576px){.recent-posts{margin-top:20px}.recent-posts .row .col:last-child{margin-bottom:0}}.tag__head{margin:40px 0}@media only screen and (max-width: 1024px){.tag__head{margin:10px 0}}.tags__inner{margin-bottom:20px}@media only screen and (max-width: 576px){.tags__inner{margin-bottom:30px}}.tag__title{margin-bottom:8px;font-size:46px;font-weight:900}@media only screen and (max-width: 576px){.tag__title{font-size:16px}}.tag__list{display:flex;align-items:center;flex-wrap:wrap;padding-bottom:20px;border-bottom:1px solid var(--background-alt-color)}.tag__list .tag__item{margin-right:12px;margin-bottom:12px}.tag__list .tag__item:last-child{margin-right:0}.tag__list .tag__link{display:block;padding:12px 16px;font-size:16px;font-weight:500;text-transform:capitalize;border-radius:8px;transition:none;background:var(--background-alt-color)}.tag__list .tag__link:hover{color:var(--heading-font-color)}@media only screen and (max-width: 576px){.tag__list{padding-bottom:12px}.tag__list .tag__item{margin-right:8px;margin-bottom:8px}.tag__list .tag__link{font-size:14px}}.tag__info{position:relative;display:flex;align-items:center;justify-content:space-between;margin-bottom:4px}.tag__info::after{content:"";position:absolute;z-index:-1;display:block;width:100%;height:1px;background:var(--background-alt-color);pointer-events:none}@media only screen and (max-width: 576px){.tag__info::after{content:none}}.tag__info-box{display:flex;align-items:center}.tag__counter{display:flex;flex-direction:column;align-items:center;padding:6px 12px;border-radius:8px;color:var(--heading-font-color);background:var(--background-alt-color)}.tag__counter span{font-family:"Noto Sans KR",sans-serif;font-size:32px;font-weight:700;line-height:1}.tag__counter small{font-size:16px;font-weight:500}@media only screen and (max-width: 576px){.tag__counter{display:none}}.tag__name{padding:10px 10px 10px 10px;margin-bottom:0;font-size:36px;text-transform:capitalize;background-color:var(--background-color)}.tag__name span{font-weight:400;color:var(--text-alt-color)}@media only screen and (max-width: 768px){.tag__name{font-size:32px}}@media only screen and (max-width: 576px){.tag__name{padding:12px 12px 12px 0;font-size:26px}}.top__link{padding-left:10px;font-size:18px;font-weight:500;text-decoration:underline;text-decoration-color:transparent;color:var(--link-color);transition:text-decoration .35s;background:var(--background-color)}.top__link:hover{text-decoration-color:var(--heading-font-color);color:var(--link-color-hover)}@media only screen and (max-width: 576px){.top__link{padding-left:0;font-size:16px}}

  </style>
</head>

<body>

  
    <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-2LESMFZQYN"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-2LESMFZQYN');
</script>
  

  <!-- begin header -->
<header class="header" id="top">
  <div class="container">
    <div class="row">
      <div class="header__inner col col-12">

        <div class="logo">
          <a class="logo__link" href="/">
          
            <img class="logo__image" src="../images/itmo.png" alt="ITMO Brain">
          
          </a>
        </div>

        <nav class="main-nav">
          <div class="main-nav__box">
            <div class="nav__icon-close">
              <i class="ion ion-md-close"></i>
            </div>
            <div class="nav__title">Menu</div>
            <ul class="nav__list list-reset">
              <li class="nav__item">
                <a href="/" class="nav__link">Trang chủ</a>
              </li>
              
                
              
                
                  
                  <li class="nav__item">
                    <a href="/about/" class="nav__link">ITMO Brain</a>
                  </li>
                  
                
              
                
                  
                  <li class="nav__item">
                    <a href="/contact/" class="nav__link">Liên hệ</a>
                  </li>
                  
                
              
                
                  
                  <li class="nav__item">
                    <a href="/cpp/" class="nav__link">CPP Course</a>
                  </li>
                  
                
              
                
              
                
                  
                
              
                
                  
                
              
                
                  
                  <li class="nav__item">
                    <a href="/cv/" class="nav__link">CV</a>
                  </li>
                  
                
              
                
                  
                  <li class="nav__item">
                    <a href="/nlp/" class="nav__link">NLP</a>
                  </li>
                  
                
              
                
                  
                
              
                
              
                
                  
                
              
                
                  
                
              
                
                  
                
              
              
              <li class="nav__item nav__item-icon">
                <div class="toggle-theme">
                  <div class="toggle-moon" title="Enable dark mode"><i class="ion ion-ios-moon"></i></div>
                  <div class="toggle-sun" title="Enable light mode"><i class="ion ion-ios-sunny"></i></div>
                </div>
              </li>
              
            </ul>
          </div>
        </nav>

        <div class="nav-button">
          <i class="nav__icon icon__menu ion ion-md-menu"></i>
          <i class="nav__icon icon__search ion ion-md-search"></i>
        </div>

      </div>
    </div>
  </div>
</header>
<!-- end header -->

<!-- begin search -->
<div class="search">
  <div class="container">
    <div class="row">
      <div class="col col-12">
        <div class="search__box">
          <div class="search__group">
            <div class="search__close">
              <i class="ion ion-md-close"></i>
            </div>
            <label for="js-search-input" class="screen-reader-text">Search for Blog</label>
            <input type="text" id="js-search-input" class="search__text" autocomplete="off" placeholder="Type to search...">
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row search-results-list" id="js-results-container"></div>
  </div>

</div>
<!-- end search -->

  <!-- begin content -->
  <main class="content" aria-label="Content">
    <div class="page-head">
  <div class="container">
    <div class="row">

      

      
      <div class="col col-12">
        <div class="page-image">
          <img class="lazy" data-src="/images/nlp.png" alt="NLP">
        </div>
      </div>
      

      

      <div class="col col-12">
        <div class="page__info">
          <h1 class="page__title">NLP</h1>
        </div>
      </div>
    </div>
  </div>
</div>

<!-- begin page -->
<div class="container animate">

  <article class="page">
    <div class="page__content">
      <blockquote>
  <p><cite>🔥Machine Learning Course🔥
<br />Neutral Network Processing</cite></p>
</blockquote>

<p>NLP là một chủ đề rất hot trong thời gian vừa qua, theo các chuyên gia thì 2020 là năm của  NLP khi mà hàng loạt các công trình quan trọng đồng loạt được công bố, cải thiện đáng kể hiệu quả của việc đọc hiểu ngôn ngữ tự nhiên.  Bài viết này tập trung vào việc trang bị cho bạn hiểu biết tổng quan về xử lí ngôn ngữ tự nhiên, bạn hoàn toàn có thể FROM ZERO TO HERO với những kiến thức ở trong bài viết này. <br /><br /></p>

<h1 id="contents">Contents</h1>

<p>Trong bài viết này tôi bắt đầu với những kiến thức rất cơ bản về RNN và sử dụng những kiến thức hiện đại nhất thời điểm hiện nay. Nội dung bài viết bao gồm:</p>
<ul>
  <li>Simple RNN’s(mạng hồi tiếp đơn giản)</li>
  <li>Word Embeddings : Đinh nghĩa và cách sử dụng</li>
  <li>LSTM’s</li>
  <li>GRU’s</li>
  <li>BI-Directional RNN’s</li>
  <li>Encoder-Decoder Models (Seq2Seq Models)</li>
  <li>Attention Models (Cơ chế chú ý)</li>
  <li>Transformers - Attention is all you need</li>
  <li>BERT</li>
</ul>

<p>Tôi chia mỗi chủ đề theo cấu trúc như sau:</p>
<ul>
  <li>Tổng quan cơ bản</li>
  <li>Hiểu sâu hơn : Tôi sẽ dẫn các đường link để bạn tự tìm hiểu.</li>
  <li>Code-Implementation</li>
  <li>Giải thích Code</li>
</ul>

<p>Đây là một bài viết tâm huyết và tôi hứa với bạn sẽ học được tất cả các công nghệ hoàn toàn với nó.</p>

<p>**<span style="color:Red">Bài viết này cần rất nhiều nỗ lực, vui lòng like và share nếu bạn cảm thấy nó hữu ích**</span></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span> <span class="c1"># linear algebra
</span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span> <span class="c1"># data processing, CSV file I/O (e.g. pd.read_csv)
</span><span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers.recurrent</span> <span class="kn">import</span> <span class="n">LSTM</span><span class="p">,</span> <span class="n">GRU</span><span class="p">,</span><span class="n">SimpleRNN</span>
<span class="kn">from</span> <span class="nn">keras.layers.core</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Activation</span><span class="p">,</span> <span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">keras.layers.embeddings</span> <span class="kn">import</span> <span class="n">Embedding</span>
<span class="kn">from</span> <span class="nn">keras.layers.normalization</span> <span class="kn">import</span> <span class="n">BatchNormalization</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">np_utils</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span><span class="p">,</span> <span class="n">decomposition</span><span class="p">,</span> <span class="n">model_selection</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">pipeline</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">GlobalMaxPooling1D</span><span class="p">,</span> <span class="n">Conv1D</span><span class="p">,</span> <span class="n">MaxPooling1D</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Bidirectional</span><span class="p">,</span> <span class="n">SpatialDropout1D</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing</span> <span class="kn">import</span> <span class="n">sequence</span><span class="p">,</span> <span class="n">text</span>
<span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="kn">import</span> <span class="n">EarlyStopping</span>


<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">from</span> <span class="nn">plotly</span> <span class="kn">import</span> <span class="n">graph_objs</span> <span class="k">as</span> <span class="n">go</span>
<span class="kn">import</span> <span class="nn">plotly.express</span> <span class="k">as</span> <span class="n">px</span>
<span class="kn">import</span> <span class="nn">plotly.figure_factory</span> <span class="k">as</span> <span class="n">ff</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Using TensorFlow backend.
</code></pre></div></div>

<h1 id="configuring-tpus">Configuring TPU’s</h1>

<p>TPU là phần cứng cho phép tính toán song song, được tối ưu hoàn toàn cho Deep Learning từ Google. Bài viết này sử dụng TPU với Tensorflow để xây dựng BERT model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Detect hardware, return appropriate distribution strategy
</span><span class="k">try</span><span class="p">:</span>
    <span class="c1"># TPU detection. No parameters necessary if TPU_NAME environment variable is
</span>    <span class="c1"># set: this is always the case on Kaggle.
</span>    <span class="n">tpu</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="n">cluster_resolver</span><span class="p">.</span><span class="n">TPUClusterResolver</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="s">'Running on TPU '</span><span class="p">,</span> <span class="n">tpu</span><span class="p">.</span><span class="n">master</span><span class="p">())</span>
<span class="k">except</span> <span class="nb">ValueError</span><span class="p">:</span>
    <span class="n">tpu</span> <span class="o">=</span> <span class="bp">None</span>

<span class="k">if</span> <span class="n">tpu</span><span class="p">:</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">config</span><span class="p">.</span><span class="n">experimental_connect_to_cluster</span><span class="p">(</span><span class="n">tpu</span><span class="p">)</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">tpu</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">initialize_tpu_system</span><span class="p">(</span><span class="n">tpu</span><span class="p">)</span>
    <span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">TPUStrategy</span><span class="p">(</span><span class="n">tpu</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># Default distribution strategy in Tensorflow. Works on CPU and single GPU.
</span>    <span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">distribute</span><span class="p">.</span><span class="n">get_strategy</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s">"REPLICAS: "</span><span class="p">,</span> <span class="n">strategy</span><span class="p">.</span><span class="n">num_replicas_in_sync</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Running on TPU  grpc://10.0.0.2:8470
REPLICAS:  8
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv'</span><span class="p">)</span>
<span class="n">validation</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation.csv'</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test.csv'</span><span class="p">)</span>
</code></pre></div></div>

<p>We will drop the other columns and approach this problem as a Binary Classification Problem and also we will have our exercise done on a smaller subsection of the dataset(only 12000 data points) to make it easier to train the models</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">'severe_toxic'</span><span class="p">,</span><span class="s">'obscene'</span><span class="p">,</span><span class="s">'threat'</span><span class="p">,</span><span class="s">'insult'</span><span class="p">,</span><span class="s">'identity_hate'</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">loc</span><span class="p">[:</span><span class="mi">12000</span><span class="p">,:]</span>
<span class="n">train</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(12001, 3)
</code></pre></div></div>

<p>We will check the maximum number of words that can be present in a comment , this will help us in padding later</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train</span><span class="p">[</span><span class="s">'comment_text'</span><span class="p">].</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="nb">len</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">).</span><span class="n">split</span><span class="p">())).</span><span class="nb">max</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>1403
</code></pre></div></div>

<p>Writing a function for getting auc score for validation</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">roc_auc</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span><span class="n">target</span><span class="p">):</span>
    <span class="s">'''
    This methods returns the AUC Score when given the Predictions
    and Labels
    '''</span>
    
    <span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">,</span> <span class="n">thresholds</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">.</span><span class="n">roc_curve</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span>
    <span class="n">roc_auc</span> <span class="o">=</span> <span class="n">metrics</span><span class="p">.</span><span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">roc_auc</span>
</code></pre></div></div>

<h3 id="data-preparation">Data Preparation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xtrain</span><span class="p">,</span> <span class="n">xvalid</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">yvalid</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">comment_text</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">train</span><span class="p">.</span><span class="n">toxic</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> 
                                                  <span class="n">stratify</span><span class="o">=</span><span class="n">train</span><span class="p">.</span><span class="n">toxic</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> 
                                                  <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> 
                                                  <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="trước-khi-bắt-đầu">Trước khi bắt đầu</h1>

<p>Trước khi chúng ta bắt đầu, nếu bạn hoàn toàn mới tìm hiểu về NLP, vui lòng đọc những kernel sau để bắt đầu con đường tìm hiểu ngôn ngữ tự nhiên cùng chúng tôi:</p>
<ul>
  <li>https://www.kaggle.com/arthurtok/spooky-nlp-and-topic-modelling-tutorial</li>
  <li>https://www.kaggle.com/abhishek/approaching-almost-any-nlp-problem-on-kaggle</li>
</ul>

<p>Nếu bạn muốn bắt đầu bằng một cách cơ bản hơn, đây là một sự lựa chọn tốt:</p>
<ul>
  <li>https://www.kaggle.com/tanulsingh077/what-s-cooking</li>
</ul>

<p>Dưới đây là những tài nguyên cơ bản để bắt đầu với những kiến thức cơ bản về mạng thần kinh nhân tạo, Chúng sẽ giúp bạn hiểu các phần tiếp theo:</p>
<ul>
  <li>https://www.youtube.com/watch?v=aircAruvnKk&amp;list=PL_h2yd2CGtBHEKwEH5iqTZH85wLS-eUzv</li>
  <li>https://www.youtube.com/watch?v=IHZwWFHWa-w&amp;list=PL_h2yd2CGtBHEKwEH5iqTZH85wLS-eUzv&amp;index=2</li>
  <li>https://www.youtube.com/watch?v=Ilg3gGewQ5U&amp;list=PL_h2yd2CGtBHEKwEH5iqTZH85wLS-eUzv&amp;index=3</li>
  <li>https://www.youtube.com/watch?v=tIeHLnjs5U8&amp;list=PL_h2yd2CGtBHEKwEH5iqTZH85wLS-eUzv&amp;index=4</li>
</ul>

<p>Để học cách trực quan hóa dữ liệu, vui lòng tham khảo:</p>
<ul>
  <li>https://www.kaggle.com/tanulsingh077/twitter-sentiment-extaction-analysis-eda-and-model</li>
  <li>https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda</li>
</ul>

<h1 id="simple-rnn">Simple RNN</h1>

<h2 id="basic-overview">Basic Overview</h2>

<p>What is a RNN?</p>

<p>Recurrent Neural Network(RNN)  là một loại Neural Network khi mà đầu ta của bước phía trược là đầu vào của bước tiếp theo. Trong một mạng thần kinh cổ điển, tất cả đầu vào và đầu ra độc lập với nhau, nhưng trong trường hợp này khi bạn cần dự đoán từ tiếp theo trong câu, những từ phía trước là cần thiết và việc ghi nhớ nó là bắt buộc. RNN giải quyết vấn đề này, giúp cho NN có thể liên kết các từ đầu vào tốt hơn.</p>

<p>Why RNN’s?</p>

<p>https://www.quora.com/Why-do-we-use-an-RNN-instead-of-a-simple-neural-network</p>

<h2 id="in-depth-understanding">In-Depth Understanding</h2>

<ul>
  <li>https://medium.com/mindorks/understanding-the-recurrent-neural-network-44d593f112a2</li>
  <li>https://www.youtube.com/watch?v=2E65LDnM2cA&amp;list=PL1F3ABbhcqa3BBWo170U4Ev2wfsF7FN8l</li>
  <li>https://www.d2l.ai/chapter_recurrent-neural-networks/rnn.html</li>
</ul>

<h2 id="code-implementation">Code Implementation</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># using keras tokenizer here
</span><span class="n">token</span> <span class="o">=</span> <span class="n">text</span><span class="p">.</span><span class="n">Tokenizer</span><span class="p">(</span><span class="n">num_words</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">1500</span>

<span class="n">token</span><span class="p">.</span><span class="n">fit_on_texts</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">xtrain</span><span class="p">)</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">xvalid</span><span class="p">))</span>
<span class="n">xtrain_seq</span> <span class="o">=</span> <span class="n">token</span><span class="p">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">xtrain</span><span class="p">)</span>
<span class="n">xvalid_seq</span> <span class="o">=</span> <span class="n">token</span><span class="p">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">xvalid</span><span class="p">)</span>

<span class="c1">#zero pad the sequences
</span><span class="n">xtrain_pad</span> <span class="o">=</span> <span class="n">sequence</span><span class="p">.</span><span class="n">pad_sequences</span><span class="p">(</span><span class="n">xtrain_seq</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">max_len</span><span class="p">)</span>
<span class="n">xvalid_pad</span> <span class="o">=</span> <span class="n">sequence</span><span class="p">.</span><span class="n">pad_sequences</span><span class="p">(</span><span class="n">xvalid_seq</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">max_len</span><span class="p">)</span>

<span class="n">word_index</span> <span class="o">=</span> <span class="n">token</span><span class="p">.</span><span class="n">word_index</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>
<span class="k">with</span> <span class="n">strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">():</span>
    <span class="c1"># A simpleRNN without any pretrained embeddings and one dense layer
</span>    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word_index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                     <span class="mi">300</span><span class="p">,</span>
                     <span class="n">input_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">))</span>
    <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">SimpleRNN</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>
    <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">))</span>
    <span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
    
<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_1 (Embedding)      (None, 1500, 300)         13049100  
_________________________________________________________________
simple_rnn_1 (SimpleRNN)     (None, 100)               40100     
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 101       
=================================================================
Total params: 13,089,301
Trainable params: 13,089,301
Non-trainable params: 0
_________________________________________________________________
CPU times: user 620 ms, sys: 370 ms, total: 990 ms
Wall time: 1.18 s
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xtrain_pad</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">nb_epoch</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="o">*</span><span class="n">strategy</span><span class="p">.</span><span class="n">num_replicas_in_sync</span><span class="p">)</span> <span class="c1">#Multiplying by Strategy to run on TPU's
</span></code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning:

The `nb_epoch` argument in `fit` has been renamed `epochs`.



Epoch 1/5
9600/9600 [==============================] - 39s 4ms/step - loss: 0.3714 - accuracy: 0.8805
Epoch 2/5
9600/9600 [==============================] - 39s 4ms/step - loss: 0.2858 - accuracy: 0.9055
Epoch 3/5
9600/9600 [==============================] - 40s 4ms/step - loss: 0.2748 - accuracy: 0.8945
Epoch 4/5
9600/9600 [==============================] - 40s 4ms/step - loss: 0.2416 - accuracy: 0.9053
Epoch 5/5
9600/9600 [==============================] - 39s 4ms/step - loss: 0.2109 - accuracy: 0.9079





&lt;keras.callbacks.callbacks.History at 0x7fae866d75c0&gt;
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scores</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xvalid_pad</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Auc: %.2f%%"</span> <span class="o">%</span> <span class="p">(</span><span class="n">roc_auc</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span><span class="n">yvalid</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Auc: 0.69%
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scores_model</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">scores_model</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">'Model'</span><span class="p">:</span> <span class="s">'SimpleRNN'</span><span class="p">,</span><span class="s">'AUC_Score'</span><span class="p">:</span> <span class="n">roc_auc</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span><span class="n">yvalid</span><span class="p">)})</span>
</code></pre></div></div>

<h2 id="code-explanantion">Code Explanantion</h2>
<ul>
  <li>Tokenization<br /><br />
Vậy nếu bạn đã xem video hoặc link chúng tôi gợi ý, bạn sẽ thấy đầu vào của RNN là một câu với các từ liên tiếp nhau. Chúng tôi đại diện mỗi từ bằng một vector one-hot với số chiều là: (Số từ trong từ điển)x1. <br />
What keras Tokenizer does is , it takes all the unique words in the corpus,forms a dictionary with words as keys and their number of occurences as values,it then sorts the dictionary in descending order of counts. It then assigns the first value 1 , second value 2 and so on. So let’s suppose word ‘the’ occured the most in the corpus then it will assigned index 1 and vector representing ‘the’ would be a one-hot vector with value 1 at position 1 and rest zereos.<br />
Try printing first 2 elements of xtrain_seq you will see every word is represented as a digit now</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xtrain_seq</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[[664,
  65,
  7,
  19,
  2262,
  14102,
  5,
  2262,
  20439,
  6071,
  4,
  71,
  32,
  20440,
  6620,
  39,
  6,
  664,
  65,
  11,
  8,
  20441,
  1502,
  38,
  6072]]
</code></pre></div></div>

<p><b>Now you might be wondering What is padding? Why its done</b><br /><br /></p>

<p>Here is the answer :</p>
<ul>
  <li>https://www.quora.com/Which-effect-does-sequence-padding-have-on-the-training-of-a-neural-network</li>
  <li>https://machinelearningmastery.com/data-preparation-variable-length-input-sequences-sequence-prediction/</li>
  <li>https://www.coursera.org/lecture/natural-language-processing-tensorflow/padding-2Cyzs</li>
</ul>

<p>Also sometimes people might use special tokens while tokenizing like EOS(end of string) and BOS(Begining of string). Here is the reason why it’s done</p>
<ul>
  <li>https://stackoverflow.com/questions/44579161/why-do-we-do-padding-in-nlp-tasks</li>
</ul>

<p>The code token.word_index simply gives the dictionary of vocab that keras created for us</p>

<ul>
  <li>Building the Neural Network</li>
</ul>

<p>Để hiểu đầu vào và đầu ra của RNN vui lòng xem qua một bài viết rất thú vị sau: https://medium.com/@shivajbd/understanding-input-and-output-shape-in-lstm-keras-c501ee95c65e</p>

<p>The first line model.Sequential() tells keras that we will be building our network sequentially . Then we first add the Embedding layer.
Embedding layer is also a layer of neurons which takes in as input the nth dimensional one hot vector of every word and converts it into 300 dimensional vector , it gives us word embeddings similar to word2vec. We could have used word2vec but the embeddings layer learns during training to enhance the embeddings.
Next we add an 100 LSTM units without any dropout or regularization
At last we add a single neuron with sigmoid function which takes output from 100 LSTM cells (Please note we have 100 LSTM cells not layers) to predict the results and then we compile the model using adam optimizer</p>

<ul>
  <li>Comments on the model<br /><br />
We can see our model achieves an accuracy of 1 which is just insane , we are clearly overfitting I know , but this was the simplest model of all ,we can tune a lot of hyperparameters like RNN units, we can do batch normalization , dropouts etc to get better result. The point is we got an AUC score of 0.82 without much efforts and we know have learnt about RNN’s .Deep learning is really revolutionary</li>
</ul>

<h1 id="word-embeddings">Word Embeddings</h1>

<p>Khi chúng ta xây dựng mô hình RNN, chúng ta phải sử dụng word-embeddings, Vậy word-embeding là già, và cách xây dựng nó là gì?
Here is the answer :</p>
<ul>
  <li>https://www.coursera.org/learn/nlp-sequence-models/lecture/6Oq70/word-representation</li>
  <li>https://machinelearningmastery.com/what-are-word-embeddings/
<br /> <br />
The latest approach to getting word Embeddings is using pretained GLoVe or using Fasttext. Without going into too much details, I would explain how to create sentence vectors and how can we use them to create a machine learning model on top of it and since I am a fan of GloVe vectors, word2vec and fasttext. In this Notebook, I’ll be using the GloVe vectors. You can download the GloVe vectors from here http://www-nlp.stanford.edu/data/glove.840B.300d.zip or you can search for GloVe in datasets on Kaggle and add the file</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># load the GloVe vectors in a dictionary:
</span>
<span class="n">embeddings_index</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s">'/kaggle/input/glove840b300dtxt/glove.840B.300d.txt'</span><span class="p">,</span><span class="s">'r'</span><span class="p">,</span><span class="n">encoding</span><span class="o">=</span><span class="s">'utf-8'</span><span class="p">)</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">f</span><span class="p">):</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">line</span><span class="p">.</span><span class="n">split</span><span class="p">(</span><span class="s">' '</span><span class="p">)</span>
    <span class="n">word</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">coefs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">asarray</span><span class="p">([</span><span class="nb">float</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">:]])</span>
    <span class="n">embeddings_index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">coefs</span>
<span class="n">f</span><span class="p">.</span><span class="n">close</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s">'Found %s word vectors.'</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">embeddings_index</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2196018it [06:43, 5439.09it/s]

Found 2196017 word vectors.
</code></pre></div></div>

<h1 id="lstms">LSTM’s</h1>

<h2 id="basic-overview-1">Basic Overview</h2>

<p>Simple RNN’s were certainly better than classical ML algorithms and gave state of the art results, but it failed to capture long term dependencies that is present in sentences . So in 1998-99 LSTM’s were introduced to counter to these drawbacks.</p>

<h2 id="in-depth-understanding-1">In Depth Understanding</h2>

<p>Why LSTM’s?</p>
<ul>
  <li>https://www.coursera.org/learn/nlp-sequence-models/lecture/PKMRR/vanishing-gradients-with-rnns</li>
  <li>https://www.analyticsvidhya.com/blog/2017/12/fundamentals-of-deep-learning-introduction-to-lstm/</li>
</ul>

<p>What are LSTM’s?</p>
<ul>
  <li>https://www.coursera.org/learn/nlp-sequence-models/lecture/KXoay/long-short-term-memory-lstm</li>
  <li>https://distill.pub/2019/memorization-in-rnns/</li>
  <li>https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21</li>
</ul>

<h1 id="code-implementation-1">Code Implementation</h1>

<p>We have already tokenized and paded our text for input to LSTM’s</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create an embedding matrix for the words we have in the dataset
</span><span class="n">embedding_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">word_index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">300</span><span class="p">))</span>
<span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">word_index</span><span class="p">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="n">embedding_vector</span> <span class="o">=</span> <span class="n">embeddings_index</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">embedding_vector</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">embedding_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">embedding_vector</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 43496/43496 [00:00&lt;00:00, 183357.18it/s]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>
<span class="k">with</span> <span class="n">strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">():</span>
    
    <span class="c1"># A simple LSTM with glove embeddings and one dense layer
</span>    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word_index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                     <span class="mi">300</span><span class="p">,</span>
                     <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="n">embedding_matrix</span><span class="p">],</span>
                     <span class="n">input_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span>
                     <span class="n">trainable</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>

    <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">recurrent_dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">))</span>
    <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">))</span>
    <span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
    
<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_2 (Embedding)      (None, 1500, 300)         13049100  
_________________________________________________________________
lstm_1 (LSTM)                (None, 100)               160400    
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 101       
=================================================================
Total params: 13,209,601
Trainable params: 160,501
Non-trainable params: 13,049,100
_________________________________________________________________
CPU times: user 1.33 s, sys: 1.46 s, total: 2.79 s
Wall time: 3.09 s
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xtrain_pad</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">nb_epoch</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="o">*</span><span class="n">strategy</span><span class="p">.</span><span class="n">num_replicas_in_sync</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning:

The `nb_epoch` argument in `fit` has been renamed `epochs`.



Epoch 1/5
9600/9600 [==============================] - 117s 12ms/step - loss: 0.3525 - accuracy: 0.8852
Epoch 2/5
9600/9600 [==============================] - 114s 12ms/step - loss: 0.2397 - accuracy: 0.9192
Epoch 3/5
9600/9600 [==============================] - 114s 12ms/step - loss: 0.1904 - accuracy: 0.9333
Epoch 4/5
9600/9600 [==============================] - 114s 12ms/step - loss: 0.1659 - accuracy: 0.9394
Epoch 5/5
9600/9600 [==============================] - 114s 12ms/step - loss: 0.1553 - accuracy: 0.9470





&lt;keras.callbacks.callbacks.History at 0x7fae84dac710&gt;
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scores</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xvalid_pad</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Auc: %.2f%%"</span> <span class="o">%</span> <span class="p">(</span><span class="n">roc_auc</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span><span class="n">yvalid</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Auc: 0.96%
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scores_model</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">'Model'</span><span class="p">:</span> <span class="s">'LSTM'</span><span class="p">,</span><span class="s">'AUC_Score'</span><span class="p">:</span> <span class="n">roc_auc</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span><span class="n">yvalid</span><span class="p">)})</span>
</code></pre></div></div>

<h2 id="code-explanation">Code Explanation</h2>

<p>As a first step we calculate embedding matrix for our vocabulary from the pretrained GLoVe vectors . Then while building the embedding layer we pass Embedding Matrix as weights to the layer instead of training it over Vocabulary and thus we pass trainable = False.
Rest of the model is same as before except we have replaced the SimpleRNN By LSTM Units</p>

<ul>
  <li>Comments on the Model</li>
</ul>

<p>We now see that the model is not overfitting and achieves an auc score of 0.96 which is quite commendable , also we close in on the gap between accuracy and auc .
We see that in this case we used dropout and prevented overfitting the data</p>

<h1 id="grus">GRU’s</h1>

<h2 id="basic--overview">Basic  Overview</h2>

<p>Introduced by Cho, et al. in 2014, GRU (Gated Recurrent Unit) sử dụng để giải quyết vấn đề mất mát gradient. GRU’s are a variation on the LSTM because both are designed similarly and, in some cases, produce equally excellent results . GRU’s were designed to be simpler and faster than LSTM’s and in most cases produce equally good results and thus there is no clear winner.</p>

<h2 id="in-depth-explanation">In Depth Explanation</h2>

<ul>
  <li>https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be</li>
  <li>https://www.coursera.org/learn/nlp-sequence-models/lecture/agZiL/gated-recurrent-unit-gru</li>
  <li>https://www.geeksforgeeks.org/gated-recurrent-unit-networks/</li>
</ul>

<h2 id="code-implementation-2">Code Implementation</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>
<span class="k">with</span> <span class="n">strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">():</span>
    <span class="c1"># GRU with glove embeddings and two dense layers
</span>     <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
     <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word_index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                     <span class="mi">300</span><span class="p">,</span>
                     <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="n">embedding_matrix</span><span class="p">],</span>
                     <span class="n">input_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span>
                     <span class="n">trainable</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
     <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">SpatialDropout1D</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span>
     <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">GRU</span><span class="p">(</span><span class="mi">300</span><span class="p">))</span>
     <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">))</span>

     <span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>   
    
<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_3 (Embedding)      (None, 1500, 300)         13049100  
_________________________________________________________________
spatial_dropout1d_1 (Spatial (None, 1500, 300)         0         
_________________________________________________________________
gru_1 (GRU)                  (None, 300)               540900    
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 301       
=================================================================
Total params: 13,590,301
Trainable params: 541,201
Non-trainable params: 13,049,100
_________________________________________________________________
CPU times: user 1.3 s, sys: 1.29 s, total: 2.59 s
Wall time: 2.79 s
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xtrain_pad</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">nb_epoch</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="o">*</span><span class="n">strategy</span><span class="p">.</span><span class="n">num_replicas_in_sync</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning:

The `nb_epoch` argument in `fit` has been renamed `epochs`.



Epoch 1/5
9600/9600 [==============================] - 191s 20ms/step - loss: 0.3272 - accuracy: 0.8933
Epoch 2/5
9600/9600 [==============================] - 189s 20ms/step - loss: 0.2015 - accuracy: 0.9334
Epoch 3/5
9600/9600 [==============================] - 189s 20ms/step - loss: 0.1540 - accuracy: 0.9483
Epoch 4/5
9600/9600 [==============================] - 189s 20ms/step - loss: 0.1287 - accuracy: 0.9548
Epoch 5/5
9600/9600 [==============================] - 188s 20ms/step - loss: 0.1238 - accuracy: 0.9551





&lt;keras.callbacks.callbacks.History at 0x7fae5b01ed30&gt;
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scores</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xvalid_pad</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Auc: %.2f%%"</span> <span class="o">%</span> <span class="p">(</span><span class="n">roc_auc</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span><span class="n">yvalid</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Auc: 0.97%
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scores_model</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">'Model'</span><span class="p">:</span> <span class="s">'GRU'</span><span class="p">,</span><span class="s">'AUC_Score'</span><span class="p">:</span> <span class="n">roc_auc</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span><span class="n">yvalid</span><span class="p">)})</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scores_model</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[{'Model': 'SimpleRNN', 'AUC_Score': 0.6949714081921305},
 {'Model': 'LSTM', 'AUC_Score': 0.9598235453841757},
 {'Model': 'GRU', 'AUC_Score': 0.9716554069114769}]
</code></pre></div></div>

<h1 id="bi-directional-rnns">Bi-Directional RNN’s</h1>

<h2 id="in-depth-explanation-1">In Depth Explanation</h2>

<ul>
  <li>https://www.coursera.org/learn/nlp-sequence-models/lecture/fyXnn/bidirectional-rnn</li>
  <li>https://towardsdatascience.com/understanding-bidirectional-rnn-in-pytorch-5bd25a5dd66</li>
  <li>https://d2l.ai/chapter_recurrent-modern/bi-rnn.html</li>
</ul>

<h2 id="code-implementation-3">Code Implementation</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>
<span class="k">with</span> <span class="n">strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">():</span>
    <span class="c1"># A simple bidirectional LSTM with glove embeddings and one dense layer
</span>    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">word_index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                     <span class="mi">300</span><span class="p">,</span>
                     <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="n">embedding_matrix</span><span class="p">],</span>
                     <span class="n">input_length</span><span class="o">=</span><span class="n">max_len</span><span class="p">,</span>
                     <span class="n">trainable</span><span class="o">=</span><span class="bp">False</span><span class="p">))</span>
    <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">recurrent_dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)))</span>

    <span class="n">model</span><span class="p">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">))</span>
    <span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s">'adam'</span><span class="p">,</span><span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
    
    
<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
embedding_4 (Embedding)      (None, 1500, 300)         13049100  
_________________________________________________________________
bidirectional_1 (Bidirection (None, 600)               1442400   
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 601       
=================================================================
Total params: 14,492,101
Trainable params: 1,443,001
Non-trainable params: 13,049,100
_________________________________________________________________
CPU times: user 2.39 s, sys: 1.62 s, total: 4 s
Wall time: 3.41 s
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">xtrain_pad</span><span class="p">,</span> <span class="n">ytrain</span><span class="p">,</span> <span class="n">nb_epoch</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="o">*</span><span class="n">strategy</span><span class="p">.</span><span class="n">num_replicas_in_sync</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning:

The `nb_epoch` argument in `fit` has been renamed `epochs`.



Epoch 1/5
9600/9600 [==============================] - 322s 34ms/step - loss: 0.3171 - accuracy: 0.9009
Epoch 2/5
9600/9600 [==============================] - 318s 33ms/step - loss: 0.1988 - accuracy: 0.9305
Epoch 3/5
9600/9600 [==============================] - 318s 33ms/step - loss: 0.1650 - accuracy: 0.9424
Epoch 4/5
9600/9600 [==============================] - 318s 33ms/step - loss: 0.1577 - accuracy: 0.9414
Epoch 5/5
9600/9600 [==============================] - 319s 33ms/step - loss: 0.1540 - accuracy: 0.9459





&lt;keras.callbacks.callbacks.History at 0x7fae5a4ade48&gt;
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scores</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">xvalid_pad</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Auc: %.2f%%"</span> <span class="o">%</span> <span class="p">(</span><span class="n">roc_auc</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span><span class="n">yvalid</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Auc: 0.97%
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">scores_model</span><span class="p">.</span><span class="n">append</span><span class="p">({</span><span class="s">'Model'</span><span class="p">:</span> <span class="s">'Bi-directional LSTM'</span><span class="p">,</span><span class="s">'AUC_Score'</span><span class="p">:</span> <span class="n">roc_auc</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span><span class="n">yvalid</span><span class="p">)})</span>
</code></pre></div></div>

<h2 id="code-explanation-1">Code Explanation</h2>

<p>Code is same as before,only we have added bidirectional nature to the LSTM cells we used before and is self explanatory. We have achieve similar accuracy and auc score as before and now we have learned all the types of typical RNN architectures</p>

<p><strong>We are now at the end of part 1 of this notebook and things are about to go wild now as we Enter more complex and State of the art models .If you have followed along from the starting and read all the articles and understood everything , these complex models would be fairly easy to understand.I recommend Finishing Part 1 before continuing as the upcoming techniques can be quite overwhelming</strong></p>

<h1 id="seq2seq-model-architecture">Seq2Seq Model Architecture</h1>

<h2 id="overview">Overview</h2>

<p>RNN’s are of many types  and different architectures are used for different purposes. Here is a nice video explanining different types of model architectures : https://www.coursera.org/learn/nlp-sequence-models/lecture/BO8PS/different-types-of-rnns.
Seq2Seq is a many to many RNN architecture where the input is a sequence and the output is also a sequence (where input and output sequences can be or cannot be of different lengths). This architecture is used in a lot of applications like Machine Translation, text summarization, question answering etc</p>

<h2 id="in-depth-understanding-2">In Depth Understanding</h2>

<p>I will not write the code implementation for this,but rather I will provide the resources where code has already been implemented and explained in a much better way than I could have ever explained.</p>

<ul>
  <li>
    <p>https://www.coursera.org/learn/nlp-sequence-models/lecture/HyEui/basic-models —&gt; A basic idea of different Seq2Seq Models</p>
  </li>
  <li>
    <p>https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html , https://machinelearningmastery.com/define-encoder-decoder-sequence-sequence-model-neural-machine-translation-keras/ —&gt; Basic Encoder-Decoder Model and its explanation respectively</p>
  </li>
  <li>
    <p>https://towardsdatascience.com/how-to-implement-seq2seq-lstm-model-in-keras-shortcutnlp-6f355f3e5639 —&gt; A More advanced Seq2seq Model and its explanation</p>
  </li>
  <li>
    <p>https://d2l.ai/chapter_recurrent-modern/machine-translation-and-dataset.html , https://d2l.ai/chapter_recurrent-modern/encoder-decoder.html —&gt; Implementation of Encoder-Decoder Model from scratch</p>
  </li>
  <li>
    <p>https://www.youtube.com/watch?v=IfsjMg4fLWQ&amp;list=PLtmWHNX-gukKocXQOkQjuVxglSDYWsSh9&amp;index=8&amp;t=0s —&gt; Introduction to Seq2seq By fast.ai</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Visualization of Results obtained from various Deep learning models
</span><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scores_model</span><span class="p">).</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s">'AUC_Score'</span><span class="p">,</span><span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">results</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="n">background_gradient</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s">'Blues'</span><span class="p">)</span>
</code></pre></div></div>

<style type="text/css">
    #T_81e3fa40_7db4_11ea_96d7_0242ac130202row0_col1 {
            background-color:  #08306b;
            color:  #f1f1f1;
        }    #T_81e3fa40_7db4_11ea_96d7_0242ac130202row1_col1 {
            background-color:  #083471;
            color:  #f1f1f1;
        }    #T_81e3fa40_7db4_11ea_96d7_0242ac130202row2_col1 {
            background-color:  #083a7a;
            color:  #f1f1f1;
        }    #T_81e3fa40_7db4_11ea_96d7_0242ac130202row3_col1 {
            background-color:  #f7fbff;
            color:  #000000;
        }</style>
<table id="T_81e3fa40_7db4_11ea_96d7_0242ac130202"><thead>    <tr>        <th class="blank level0"></th>        <th class="col_heading level0 col0">Model</th>        <th class="col_heading level0 col1">AUC_Score</th>    </tr></thead><tbody>
                <tr>
                        <th id="T_81e3fa40_7db4_11ea_96d7_0242ac130202level0_row0" class="row_heading level0 row0">2</th>
                        <td id="T_81e3fa40_7db4_11ea_96d7_0242ac130202row0_col0" class="data row0 col0">GRU</td>
                        <td id="T_81e3fa40_7db4_11ea_96d7_0242ac130202row0_col1" class="data row0 col1">0.971655</td>
            </tr>
            <tr>
                        <th id="T_81e3fa40_7db4_11ea_96d7_0242ac130202level0_row1" class="row_heading level0 row1">3</th>
                        <td id="T_81e3fa40_7db4_11ea_96d7_0242ac130202row1_col0" class="data row1 col0">Bi-directional LSTM</td>
                        <td id="T_81e3fa40_7db4_11ea_96d7_0242ac130202row1_col1" class="data row1 col1">0.966693</td>
            </tr>
            <tr>
                        <th id="T_81e3fa40_7db4_11ea_96d7_0242ac130202level0_row2" class="row_heading level0 row2">1</th>
                        <td id="T_81e3fa40_7db4_11ea_96d7_0242ac130202row2_col0" class="data row2 col0">LSTM</td>
                        <td id="T_81e3fa40_7db4_11ea_96d7_0242ac130202row2_col1" class="data row2 col1">0.959824</td>
            </tr>
            <tr>
                        <th id="T_81e3fa40_7db4_11ea_96d7_0242ac130202level0_row3" class="row_heading level0 row3">0</th>
                        <td id="T_81e3fa40_7db4_11ea_96d7_0242ac130202row3_col0" class="data row3 col0">SimpleRNN</td>
                        <td id="T_81e3fa40_7db4_11ea_96d7_0242ac130202row3_col1" class="data row3 col1">0.694971</td>
            </tr>
    </tbody></table>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span> <span class="o">=</span> <span class="n">go</span><span class="p">.</span><span class="n">Figure</span><span class="p">(</span><span class="n">go</span><span class="p">.</span><span class="n">Funnelarea</span><span class="p">(</span>
    <span class="n">text</span> <span class="o">=</span><span class="n">results</span><span class="p">.</span><span class="n">Model</span><span class="p">,</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">results</span><span class="p">.</span><span class="n">AUC_Score</span><span class="p">,</span>
    <span class="n">title</span> <span class="o">=</span> <span class="p">{</span><span class="s">"position"</span><span class="p">:</span> <span class="s">"top center"</span><span class="p">,</span> <span class="s">"text"</span><span class="p">:</span> <span class="s">"Funnel-Chart of Sentiment Distribution"</span><span class="p">}</span>
    <span class="p">))</span>
<span class="n">fig</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<h1 id="attention-models">Attention Models</h1>

<p>Đây là phần giá trị và hấp dẫn nhất của bài viết. Nếu bạn hiểu cách vận hành của attention block, understanding transformers and transformer based architectures như BERT thì sẽ thật dễ hiểu, nhưng nếu không thì cũng không sao, tôi sẽ chia sẻ cho bạn nhiều nguồn để bù đắp vấn đề này. :-</p>

<ul>
  <li>https://www.coursera.org/learn/nlp-sequence-models/lecture/RDXpX/attention-model-intuition –&gt; Only watch this video and not the next one</li>
  <li>https://towardsdatascience.com/sequence-2-sequence-model-with-attention-mechanism-9e9ca2a613a</li>
  <li>https://towardsdatascience.com/attention-and-its-different-forms-7fc3674d14dc</li>
  <li>https://distill.pub/2016/augmented-rnns/</li>
</ul>

<h2 id="code-implementation-4">Code Implementation</h2>

<ul>
  <li>https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/ –&gt; Basic Level</li>
  <li>https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html —&gt; Implementation from Scratch in Pytorch</li>
</ul>

<h1 id="transformers--attention-is-all-you-need">Transformers : Attention is all you need</h1>

<p>So finally we have reached the end of the learning curve and are about to start learning the technology that changed NLP completely and are the reasons for the state of the art NLP techniques .Transformers were introduced in the paper Attention is all you need by Google. If you have understood the Attention models,this will be very easy , Here is transformers fully explained:</p>

<ul>
  <li>http://jalammar.github.io/illustrated-transformer/</li>
</ul>

<h2 id="code-implementation-5">Code Implementation</h2>

<ul>
  <li>http://nlp.seas.harvard.edu/2018/04/03/attention.html —&gt; This presents the code implementation of the architecture presented in the paper by Google</li>
</ul>

<h1 id="bert-and-its-implementation-on-this-competition">BERT and Its Implementation on this Competition</h1>

<p>Tôi chắc chắn rằng tài liệu sau sẽ giúp bạn hiểu hơn về BERT là kiến trúc NLP phổ biến nhất hiện tại:-</p>

<ul>
  <li>http://jalammar.github.io/illustrated-bert/ —&gt; In Depth Understanding of BERT</li>
</ul>

<p>Sau khi đi qua bài viết trên, tôi chắc rằng bạn đã hiểu về transformer. Chúng được dùng theo hai cách sau đây :<br /><br />
1) Sử dụng model được huấn luyện trước mà không đào tạo lại</p>
<ul>
  <li>EG: http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/ —&gt; Using Pre-trained BERT without Tuning</li>
</ul>

<p>2) Sử dụng mô hình đào tạo trước để fine-tuning cho một vấn đề bé hơn</p>
<ul>
  <li>EG:* https://www.youtube.com/watch?v=hinZO–TEk4&amp;t=2933s —&gt; Tuning BERT For your TASK</li>
</ul>

<p>We will be using the first example as a base for our implementation of BERT model using Hugging Face and KERAS , but contrary to first example we will also Fine-Tune our model for our task</p>

<p>Acknowledgements : https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras</p>

<p>Các bước thực hiện:</p>
<ul>
  <li>Chuẩn bị dữ liệu : Tokenization and encoding of data</li>
  <li>Cấu hình TPU</li>
  <li>Tạo model và mạng NN</li>
  <li>Train model và lấy kết quả</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Loading Dependencies
</span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Input</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Model</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.callbacks</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span>
<span class="kn">from</span> <span class="nn">kaggle_datasets</span> <span class="kn">import</span> <span class="n">KaggleDatasets</span>
<span class="kn">import</span> <span class="nn">transformers</span>

<span class="kn">from</span> <span class="nn">tokenizers</span> <span class="kn">import</span> <span class="n">BertWordPieceTokenizer</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># LOADING THE DATA
</span>
<span class="n">train1</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv"</span><span class="p">)</span>
<span class="n">valid</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation.csv'</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test.csv'</span><span class="p">)</span>
<span class="n">sub</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'/kaggle/input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv'</span><span class="p">)</span>
</code></pre></div></div>

<p>Encoder FOr DATA for understanding waht encode batch does read documentation of hugging face tokenizer :
https://huggingface.co/transformers/main_classes/tokenizer.html here</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">fast_encode</span><span class="p">(</span><span class="n">texts</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">chunk_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="mi">512</span><span class="p">):</span>
    <span class="s">"""
    Encoder for encoding the text into sequence of integers for BERT Input
    """</span>
    <span class="n">tokenizer</span><span class="p">.</span><span class="n">enable_truncation</span><span class="p">(</span><span class="n">max_length</span><span class="o">=</span><span class="n">maxlen</span><span class="p">)</span>
    <span class="n">tokenizer</span><span class="p">.</span><span class="n">enable_padding</span><span class="p">(</span><span class="n">max_length</span><span class="o">=</span><span class="n">maxlen</span><span class="p">)</span>
    <span class="n">all_ids</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">texts</span><span class="p">),</span> <span class="n">chunk_size</span><span class="p">)):</span>
        <span class="n">text_chunk</span> <span class="o">=</span> <span class="n">texts</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">chunk_size</span><span class="p">].</span><span class="n">tolist</span><span class="p">()</span>
        <span class="n">encs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">.</span><span class="n">encode_batch</span><span class="p">(</span><span class="n">text_chunk</span><span class="p">)</span>
        <span class="n">all_ids</span><span class="p">.</span><span class="n">extend</span><span class="p">([</span><span class="n">enc</span><span class="p">.</span><span class="n">ids</span> <span class="k">for</span> <span class="n">enc</span> <span class="ow">in</span> <span class="n">encs</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">all_ids</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#IMP DATA FOR CONFIG
</span>
<span class="n">AUTO</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">experimental</span><span class="p">.</span><span class="n">AUTOTUNE</span>


<span class="c1"># Configuration
</span><span class="n">EPOCHS</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">16</span> <span class="o">*</span> <span class="n">strategy</span><span class="p">.</span><span class="n">num_replicas_in_sync</span>
<span class="n">MAX_LEN</span> <span class="o">=</span> <span class="mi">192</span>
</code></pre></div></div>

<h2 id="tokenization">Tokenization</h2>

<p>For understanding please refer to hugging face documentation again</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># First load the real tokenizer
</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">transformers</span><span class="p">.</span><span class="n">DistilBertTokenizer</span><span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">'distilbert-base-multilingual-cased'</span><span class="p">)</span>
<span class="c1"># Save the loaded tokenizer locally
</span><span class="n">tokenizer</span><span class="p">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="s">'.'</span><span class="p">)</span>
<span class="c1"># Reload it with the huggingface tokenizers library
</span><span class="n">fast_tokenizer</span> <span class="o">=</span> <span class="n">BertWordPieceTokenizer</span><span class="p">(</span><span class="s">'vocab.txt'</span><span class="p">,</span> <span class="n">lowercase</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">fast_tokenizer</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…








Tokenizer(vocabulary_size=119547, model=BertWordPiece, add_special_tokens=True, unk_token=[UNK], sep_token=[SEP], cls_token=[CLS], clean_text=True, handle_chinese_chars=True, strip_accents=True, lowercase=False, wordpieces_prefix=##)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">x_train</span> <span class="o">=</span> <span class="n">fast_encode</span><span class="p">(</span><span class="n">train1</span><span class="p">.</span><span class="n">comment_text</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">),</span> <span class="n">fast_tokenizer</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">)</span>
<span class="n">x_valid</span> <span class="o">=</span> <span class="n">fast_encode</span><span class="p">(</span><span class="n">valid</span><span class="p">.</span><span class="n">comment_text</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">),</span> <span class="n">fast_tokenizer</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">)</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">fast_encode</span><span class="p">(</span><span class="n">test</span><span class="p">.</span><span class="n">content</span><span class="p">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">),</span> <span class="n">fast_tokenizer</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">)</span>

<span class="n">y_train</span> <span class="o">=</span> <span class="n">train1</span><span class="p">.</span><span class="n">toxic</span><span class="p">.</span><span class="n">values</span>
<span class="n">y_valid</span> <span class="o">=</span> <span class="n">valid</span><span class="p">.</span><span class="n">toxic</span><span class="p">.</span><span class="n">values</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 874/874 [00:35&lt;00:00, 24.35it/s]
100%|██████████| 32/32 [00:01&lt;00:00, 20.87it/s]
100%|██████████| 250/250 [00:11&lt;00:00, 22.06it/s]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_dataset</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span>
    <span class="p">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
    <span class="p">.</span><span class="n">repeat</span><span class="p">()</span>
    <span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="mi">2048</span><span class="p">)</span>
    <span class="p">.</span><span class="n">batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
    <span class="p">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">AUTO</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">valid_dataset</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span>
    <span class="p">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">x_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">))</span>
    <span class="p">.</span><span class="n">batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
    <span class="p">.</span><span class="n">cache</span><span class="p">()</span>
    <span class="p">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">AUTO</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">test_dataset</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span>
    <span class="p">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
    <span class="p">.</span><span class="n">batch</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">build_model</span><span class="p">(</span><span class="n">transformer</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">512</span><span class="p">):</span>
    <span class="s">"""
    function for training the BERT model
    """</span>
    <span class="n">input_word_ids</span> <span class="o">=</span> <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">max_len</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s">"input_word_ids"</span><span class="p">)</span>
    <span class="n">sequence_output</span> <span class="o">=</span> <span class="n">transformer</span><span class="p">(</span><span class="n">input_word_ids</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">cls_token</span> <span class="o">=</span> <span class="n">sequence_output</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s">'sigmoid'</span><span class="p">)(</span><span class="n">cls_token</span><span class="p">)</span>
    
    <span class="n">model</span> <span class="o">=</span> <span class="n">Model</span><span class="p">(</span><span class="n">inputs</span><span class="o">=</span><span class="n">input_word_ids</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">out</span><span class="p">)</span>
    <span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">Adam</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">),</span> <span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">model</span>
</code></pre></div></div>

<h2 id="starting-training">Starting Training</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>
<span class="k">with</span> <span class="n">strategy</span><span class="p">.</span><span class="n">scope</span><span class="p">():</span>
    <span class="n">transformer_layer</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">transformers</span><span class="p">.</span><span class="n">TFDistilBertModel</span>
        <span class="p">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s">'distilbert-base-multilingual-cased'</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">build_model</span><span class="p">(</span><span class="n">transformer_layer</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="n">MAX_LEN</span><span class="p">)</span>
<span class="n">model</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>HBox(children=(FloatProgress(value=0.0, description='Downloading', max=618.0, style=ProgressStyle(description_…






HBox(children=(FloatProgress(value=0.0, description='Downloading', max=910749124.0, style=ProgressStyle(descri…



Model: "model"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_word_ids (InputLayer)  [(None, 192)]             0         
_________________________________________________________________
tf_distil_bert_model (TFDist ((None, 192, 768),)       134734080 
_________________________________________________________________
tf_op_layer_strided_slice (T [(None, 768)]             0         
_________________________________________________________________
dense (Dense)                (None, 1)                 769       
=================================================================
Total params: 134,734,849
Trainable params: 134,734,849
Non-trainable params: 0
_________________________________________________________________
CPU times: user 34.4 s, sys: 13.3 s, total: 47.7 s
Wall time: 50.8 s
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_steps</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">BATCH_SIZE</span>
<span class="n">train_history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train_dataset</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">n_steps</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">valid_dataset</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span>
<span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Train for 1746 steps, validate for 63 steps
Epoch 1/3
1746/1746 [==============================] - 255s 146ms/step - loss: 0.1221 - accuracy: 0.9517 - val_loss: 0.4484 - val_accuracy: 0.8479
Epoch 2/3
1746/1746 [==============================] - 198s 114ms/step - loss: 0.0908 - accuracy: 0.9634 - val_loss: 0.4769 - val_accuracy: 0.8491
Epoch 3/3
1746/1746 [==============================] - 198s 113ms/step - loss: 0.0775 - accuracy: 0.9680 - val_loss: 0.5522 - val_accuracy: 0.8500
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_steps</span> <span class="o">=</span> <span class="n">x_valid</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">BATCH_SIZE</span>
<span class="n">train_history_2</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">valid_dataset</span><span class="p">.</span><span class="n">repeat</span><span class="p">(),</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">n_steps</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">EPOCHS</span><span class="o">*</span><span class="mi">2</span>
<span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Train for 62 steps
Epoch 1/6
62/62 [==============================] - 18s 291ms/step - loss: 0.3244 - accuracy: 0.8613
Epoch 2/6
62/62 [==============================] - 25s 401ms/step - loss: 0.2354 - accuracy: 0.8955
Epoch 3/6
62/62 [==============================] - 7s 110ms/step - loss: 0.1718 - accuracy: 0.9252
Epoch 4/6
62/62 [==============================] - 7s 111ms/step - loss: 0.1210 - accuracy: 0.9492
Epoch 5/6
62/62 [==============================] - 7s 114ms/step - loss: 0.0798 - accuracy: 0.9686
Epoch 6/6
62/62 [==============================] - 7s 110ms/step - loss: 0.0765 - accuracy: 0.9696
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sub</span><span class="p">[</span><span class="s">'toxic'</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_dataset</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">sub</span><span class="p">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s">'submission.csv'</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>499/499 [==============================] - 41s 82ms/step
</code></pre></div></div>

<h1 id="end-notes">End Notes</h1>

<h3 id="một-số-tài-liệu-tham-khảo-hữu-ích">Một số tài liệu tham khảo hữu ích:</h3>

<p>1) Books</p>

<ul>
  <li>https://d2l.ai/</li>
  <li>Jason Brownlee’s Books</li>
</ul>

<p>2) Courses</p>

<ul>
  <li>https://www.coursera.org/learn/nlp-sequence-models/home/welcome</li>
  <li>Fast.ai NLP Course</li>
</ul>

<p>3) Blogs and websites</p>

<ul>
  <li>Machine Learning Mastery</li>
  <li>https://distill.pub/</li>
  <li>http://jalammar.github.io/</li>
</ul>

<p>**<span style="color:Red">This is subtle effort of contributing towards the community, if it helped you in any way please show a token of love by like it**</span></p>

<h3 id="các-giảng-viên-của-khoá-học">Các giảng viên của khoá học:</h3>
<ul>
  <li>💡Trần Đức Mạnh</li>
</ul>

<div class="gallery-box">
  <div class="gallery">
    <img src="/images/admin/manh.jpg" />
  </div>
  <em>NLP/ <a href="https://fb.com/itmobrain" target="_blank">ITMO Brain</a></em>
</div>

    </div>
  </article>

</div>
<!-- end page -->


  </main>
  <!-- end content -->

  <!-- begin footer -->
<footer class="footer">

  <div class="footer__inner">
    <div class="container">
      <div class="row">

        <div class="col col-5 col-d-12 " >
          <div class="footer__author justify-content-center" >
            <div class="footer__author-avatar">
              <img class="lazy" data-src="/images/logo.png" alt="ITMO Brain">
            </div>
            <h3 class="footer__author-name">ITMO Brain</h3>
            <p class="footer__author-bio">CLB Tin Hoc ITMO Brain, ITMO University, Russia.</br>
Trần Đức Mạnh   -   Nguyễn Văn Chuyên</br>
Đỗ Bảo Hoàng    -   Hoàng Minh Thắng</br>
Triệu Minh Tâm  -   Đinh Ngọc Tuấn</br>
Nguyễn Ngọc Đức  -  Lê Trọng Minh</br>
Lê Ngọc Thiện  -  Trần Văn Khánh</br>
</p>
            
            <div class="social">
              <ul class="social__list list-reset">
                
                <li class="social__item">
                  <a class="social__link" href="https://github.com/manhlab" target="_blank" rel="noopener"
                    aria-label=" link"><i class="ion ion-logo-github"></i></a>
                </li>
                
                <li class="social__item">
                  <a class="social__link" href="https://www.facebook.com/itmobrain" target="_blank" rel="noopener"
                    aria-label=" link"><i class="ion ion-logo-facebook"></i></a>
                </li>
                
              </ul>
            </div>
            
          </div>
        </div>

        
       <div class="col col-6 push-1 col-d-12 push-d-0">
         <div class="footer__gallery">
           <h3 class="footer__gallery-title">Thành viên ban điều hành</h3>
           
           <div class="gallery-footer">
             <div class="gallery" style="grid-template-columns: repeat(3, auto);">
               
               <div class="gallery__image">
                 <img src="/images/admin/thang.jpg" alt="Tran Duc Manh" loading="lazy">
               </div>
               
               <div class="gallery__image">
                 <img src="/images/admin/hoang.jpg" alt="Do Bao Hoang" loading="lazy">
               </div>
               
               <div class="gallery__image">
                 <img src="/images/admin/tam.jpg" alt="Trieu Tam" loading="lazy">
               </div>
               
               <div class="gallery__image">
                 <img src="/images/admin/duc.jpg" alt="Ngoc Duc" loading="lazy">
               </div>
               
               <div class="gallery__image">
                 <img src="/images/admin/thien.jpg" alt="Thien" loading="lazy">
               </div>
               
               <div class="gallery__image">
                 <img src="/images/admin/tuan.jpg" alt="Dinh Tuan" loading="lazy">
               </div>
               
               <div class="gallery__image">
                 <img src="/images/admin/minh.jpg" alt="Fashion" loading="lazy">
               </div>
               
               <div class="gallery__image">
                 <img src="/images/admin/khanh.jpg" alt="Notes" loading="lazy">
               </div>
               
               <div class="gallery__image">
                 <img src="/images/admin/manh.jpg" alt="Rest" loading="lazy">
               </div>
               
             </div>
           </div>
           
         </div>
       </div>
        

      </div>
    </div>
  </div>

  <div class="footer__info">
    <div class="container">
      <div class="row">
        <div class="col col-12">
          <div class="footer__info-box">
            <div class="copyright">2021 &copy; <a href="/">ITMO Brain</a>.</div>
            <div class="top" title="Top"><i class="ion ion-ios-arrow-up"></i></div>
          </div>
        </div>
      </div>
    </div>
  </div>

</footer>
<!-- end footer -->

  <script src="/js/scripts.js"></script>
  <script src="/js/common.js"></script>
</body>

</html>